{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [ER-190C] Homework 10: Classification Trees\n",
    "----\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "[Introduction](#intro) <br>\n",
    "[1. The Data](#data) <br>\n",
    "[2. Decision Trees From Scratch](#scratch) <br>\n",
    "[3. Implementing with Scikit-learn](#sk) <br>\n",
    "[4. Ensemble Methods](#improve) <br>\n",
    "[5. Comparing Methods](#compare) <br>\n",
    "\n",
    "**Dependencies:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import os.path\n",
    "from shutil import copyfile\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use(\"fivethirtyeight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xlrd in /anaconda3/lib/python3.6/site-packages (1.1.0)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "Requirement already satisfied: graphviz in /anaconda3/lib/python3.6/site-packages (0.10.1)\n",
      "\u001b[33mYou are using pip version 18.0, however version 18.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install xlrd\n",
    "!pip install graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Introduction <a name = 'intro'></a>\n",
    "\n",
    "Decision trees are a powerful prediction method and are easy to interpret. A decision tree can explain exactly why a specific prediction was made. They usually aren't used by themselves, but many trees are used for ensemble methods such as random forests and bagging. Trees are, overall, a relatively more accessible method for predictive modeling since they are used for both regression and classification and can take in both continuous and categorical data.\n",
    "\n",
    "In this homework, we'll be doing a brief exploration of the CalEnviroScreen dataset, testing out how to make a tree from scratch, as well as implementing various ensemble methods using scikit-learn. It'll be a comprehensive survey of trees and the multitude of algorithms that arise from one tree!\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "## 1. The Data <a name='data'></a>\n",
    "\n",
    "In this homework, we will be working with the [California Communities Environmental Health Screening Tool (CalEnviroScreen)](https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-30), which uses demographic and environmental information to identify communities that are susceptible to various types of pollution. The various variables in this dataset contribute to the CES score, which reflects a community's environmental conditions and its vulnerability to environmental pollutants.\n",
    "\n",
    "We worked with this dataset in lab and this will be one of two homeworks that utilize this dataset.  Although this dataset scores around 8000 of census tracts in California, we'll focus on a subset which makes the decision tree slightly more interpretable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfile(filename):\n",
    "    \n",
    "    if os.path.isfile(filename) == False: # check if you've got the file, if not, download it\n",
    "        weborlocal = input('File is not in the present working directory.  Get it from the web, or local? ')\n",
    "        \n",
    "        if weborlocal == 'web':\n",
    "            url = input('What is the url? ')\n",
    "            urllib.request.urlretrieve(url, filename);\n",
    "        \n",
    "        elif weborlocal == 'local':\n",
    "            directory = input('What\\'s the file\\'s directory? ')\n",
    "            print(directory+filename)\n",
    "            \n",
    "            if os.path.isfile(directory+filename)==True:\n",
    "                copyfile(directory+filename, filename)\n",
    "            else:\n",
    "                print('Can\\'t find the file.  Check the directory and make sure the path ends in \"/\".')\n",
    "        else:\n",
    "            print('Please choose \"web\" or \"local\".  Try again.')\n",
    "    \n",
    "    else:\n",
    "        print('That file is in the present working directory.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That file is in the present working directory.\n"
     ]
    }
   ],
   "source": [
    "filename = 'ces3results.xlsx'\n",
    "getfile(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've just obtained an excel spreadsheet of environmental data from the California EnviroScreen data set. Now, we will format the spreadsheet into a DataFrame object in order to explore its properties. \n",
    "\n",
    "Documentation on Pandas' excel methods can be found at [here](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_excel.html#pandas.read_excel).\n",
    "\n",
    "First we will focus on the first sheet, which contains the data that we'll work with in this homework; run the following cell to look at the four sheets in this excel file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CES3.0FINAL_results', 'Data Dictionary', 'Missing&NAData', 'Demographic profile']\n"
     ]
    }
   ],
   "source": [
    "xl = pd.ExcelFile(filename)\n",
    "print(xl.sheet_names) # display a list of the sheets in the spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 1.1:</b> Load the first sheet of the Excel file and assign it to the variable `df0`. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>California County</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>City</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>CES 3.0 Percentile</th>\n",
       "      <th>CES 3.0 \n",
       "Percentile Range</th>\n",
       "      <th>...</th>\n",
       "      <th>Linguistic Isolation Pctl</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Poverty Pctl</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Unemployment Pctl</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Housing Burden Pctl</th>\n",
       "      <th>Pop. Char.</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>Pop. Char. Pctl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6019001100</td>\n",
       "      <td>3174</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.781696</td>\n",
       "      <td>36.709695</td>\n",
       "      <td>94.089387</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>77.509665</td>\n",
       "      <td>76.3</td>\n",
       "      <td>97.121307</td>\n",
       "      <td>17.6</td>\n",
       "      <td>91.724838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.398324</td>\n",
       "      <td>92.120494</td>\n",
       "      <td>9.553440</td>\n",
       "      <td>99.697314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6071001600</td>\n",
       "      <td>6133</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>91761</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-117.618013</td>\n",
       "      <td>34.057780</td>\n",
       "      <td>90.677825</td>\n",
       "      <td>99.987388</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>96.253833</td>\n",
       "      <td>72.5</td>\n",
       "      <td>94.632307</td>\n",
       "      <td>12.3</td>\n",
       "      <td>71.823836</td>\n",
       "      <td>34.1</td>\n",
       "      <td>93.754760</td>\n",
       "      <td>87.436849</td>\n",
       "      <td>9.067783</td>\n",
       "      <td>98.108210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019000200</td>\n",
       "      <td>3167</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.805504</td>\n",
       "      <td>36.735491</td>\n",
       "      <td>85.968804</td>\n",
       "      <td>99.974776</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>78.389548</td>\n",
       "      <td>86.8</td>\n",
       "      <td>99.560025</td>\n",
       "      <td>16.1</td>\n",
       "      <td>87.980708</td>\n",
       "      <td>40.1</td>\n",
       "      <td>97.854785</td>\n",
       "      <td>94.581328</td>\n",
       "      <td>9.808662</td>\n",
       "      <td>99.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077000801</td>\n",
       "      <td>6692</td>\n",
       "      <td>San Joaquin</td>\n",
       "      <td>95203</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>-121.314524</td>\n",
       "      <td>37.940517</td>\n",
       "      <td>82.490978</td>\n",
       "      <td>99.962164</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>75.136648</td>\n",
       "      <td>61.3</td>\n",
       "      <td>85.568825</td>\n",
       "      <td>19.6</td>\n",
       "      <td>94.973981</td>\n",
       "      <td>21.1</td>\n",
       "      <td>63.544047</td>\n",
       "      <td>86.701266</td>\n",
       "      <td>8.991455</td>\n",
       "      <td>97.729852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6019001500</td>\n",
       "      <td>2206</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93725</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.717843</td>\n",
       "      <td>36.681600</td>\n",
       "      <td>82.030324</td>\n",
       "      <td>99.949552</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>73.723504</td>\n",
       "      <td>66.4</td>\n",
       "      <td>90.232558</td>\n",
       "      <td>18.6</td>\n",
       "      <td>93.654017</td>\n",
       "      <td>28.1</td>\n",
       "      <td>83.980706</td>\n",
       "      <td>80.075199</td>\n",
       "      <td>8.304296</td>\n",
       "      <td>92.773364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Census Tract  Total Population California County    ZIP      City  \\\n",
       "0    6019001100              3174           Fresno   93706    Fresno   \n",
       "1    6071001600              6133    San Bernardino  91761   Ontario   \n",
       "2    6019000200              3167           Fresno   93706    Fresno   \n",
       "3    6077000801              6692       San Joaquin  95203  Stockton   \n",
       "4    6019001500              2206           Fresno   93725    Fresno   \n",
       "\n",
       "    Longitude   Latitude  CES 3.0 Score   CES 3.0 Percentile  \\\n",
       "0 -119.781696  36.709695      94.089387           100.000000   \n",
       "1 -117.618013  34.057780      90.677825            99.987388   \n",
       "2 -119.805504  36.735491      85.968804            99.974776   \n",
       "3 -121.314524  37.940517      82.490978            99.962164   \n",
       "4 -119.717843  36.681600      82.030324            99.949552   \n",
       "\n",
       "  CES 3.0 \\nPercentile Range       ...         Linguistic Isolation Pctl  \\\n",
       "0   96-100% (highest scores)       ...                         77.509665   \n",
       "1   96-100% (highest scores)       ...                         96.253833   \n",
       "2   96-100% (highest scores)       ...                         78.389548   \n",
       "3   96-100% (highest scores)       ...                         75.136648   \n",
       "4   96-100% (highest scores)       ...                         73.723504   \n",
       "\n",
       "   Poverty  Poverty Pctl  Unemployment  Unemployment Pctl  Housing Burden  \\\n",
       "0     76.3     97.121307          17.6          91.724838            26.0   \n",
       "1     72.5     94.632307          12.3          71.823836            34.1   \n",
       "2     86.8     99.560025          16.1          87.980708            40.1   \n",
       "3     61.3     85.568825          19.6          94.973981            21.1   \n",
       "4     66.4     90.232558          18.6          93.654017            28.1   \n",
       "\n",
       "   Housing Burden Pctl  Pop. Char.   Pop. Char. Score  Pop. Char. Pctl  \n",
       "0            79.398324    92.120494          9.553440        99.697314  \n",
       "1            93.754760    87.436849          9.067783        98.108210  \n",
       "2            97.854785    94.581328          9.808662        99.987388  \n",
       "3            63.544047    86.701266          8.991455        97.729852  \n",
       "4            83.980706    80.075199          8.304296        92.773364  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "df0 = xl.parse(xl.sheet_names[0]) # display the first sheet as Pandas dataframe\n",
    "df0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we explore this dataset, look at some of the features -- notice that this dataset doesn't include the units of most of it's features. Let's take a look at a different sheet.\n",
    "\n",
    "Run the following cell to load the data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Description</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>For more information, see the report and acces...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CalEnviroScreen 3.0 Webpage</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A web map of the CalEnviroScreen 3.0 results i...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CalEnviroScreen 3.0 Web Map</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Variable Name</td>\n",
       "      <td>Description</td>\n",
       "      <td>CalEnviroScreen Category</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Census Tract</td>\n",
       "      <td>Census Tract ID from 2010 Census</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>2010 population in census tracts</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>California County</td>\n",
       "      <td>California county that the census tract falls ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ZIP</td>\n",
       "      <td>Postal ZIP Code that the census tract falls wi...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Variable  \\\n",
       "0  For more information, see the report and acces...   \n",
       "1                        CalEnviroScreen 3.0 Webpage   \n",
       "2  A web map of the CalEnviroScreen 3.0 results i...   \n",
       "3                        CalEnviroScreen 3.0 Web Map   \n",
       "4                                                NaN   \n",
       "5                                      Variable Name   \n",
       "6                                       Census Tract   \n",
       "7                                   Total Population   \n",
       "8                                  California County   \n",
       "9                                                ZIP   \n",
       "\n",
       "                                         Description                Unnamed: 2  \n",
       "0                                                NaN                       NaN  \n",
       "1                                                NaN                       NaN  \n",
       "2                                                NaN                       NaN  \n",
       "3                                                NaN                       NaN  \n",
       "4                                                NaN                       NaN  \n",
       "5                                        Description  CalEnviroScreen Category  \n",
       "6                   Census Tract ID from 2010 Census                       NaN  \n",
       "7                  2010 population in census tracts                        NaN  \n",
       "8  California county that the census tract falls ...                       NaN  \n",
       "9  Postal ZIP Code that the census tract falls wi...                       NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dd = xl.parse('Data Dictionary').rename(columns = {'CalEnviroScreen 3.0: Data Dictionary':'Variable', \n",
    "                                                   'Unnamed: 1': 'Description'})\n",
    "dd.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we move on, let's check the sheet we just loaded. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 1.2:</b> Does the number of columns in the first sheet correspond with the number of rows of the variables in the table we just created? Your answer should return a boolean value.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLUTION\n",
    "dd.iloc[6:62].shape[0] == df0.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've checked if the features and columns correspond, let's move on and take a closer look at the description of these variables.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 1.3:</b> In the `dd` dataframe, drop the rows that contain `Pctl` in the variable name and drop the last column  as well. Make sure the shape is correct.\n",
    "\n",
    "Note: If you don't pass, rerun the cell that loads this dataframe (two cells before this one)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "\n",
    "assert dd.shape == (35, 2 )\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Census Tract</td>\n",
       "      <td>Census Tract ID from 2010 Census</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Total Population</td>\n",
       "      <td>2010 population in census tracts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>California County</td>\n",
       "      <td>California county that the census tract falls ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZIP</td>\n",
       "      <td>Postal ZIP Code that the census tract falls wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>City</td>\n",
       "      <td>City or nearby city the the census tract falls...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Variable                                        Description\n",
       "0       Census Tract                   Census Tract ID from 2010 Census\n",
       "1   Total Population                  2010 population in census tracts \n",
       "2  California County  California county that the census tract falls ...\n",
       "3                ZIP  Postal ZIP Code that the census tract falls wi...\n",
       "4               City  City or nearby city the the census tract falls..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLTUION\n",
    "dd = dd.iloc[6:62, :2]\n",
    "dd = dd.drop([i for i in dd.index if 'Pctl' in dd.loc[i][0]]).reset_index(drop=True)\n",
    "\n",
    "assert dd.shape == (35, 2 )\n",
    "dd.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that not all of the variables have an explicit description of the unit of measurement, or are a scaled or weighted metric. Regardless, we have an idea of the variables we are working with and their units of measurement.\n",
    "\n",
    "Let's move on and take a look at the data for the city of Berkeley.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 1.4:</b> Find all instances (rows) that Berkeley appears in the dataset and assign it to the data frame `berkeley`. Then, select the columns `Census Tract`, `ZIP`, `CES 3.0 Score`, `Housing Burden`, `Poverty`, `Pesticides`, `Groundwater Threats`, and `Pollution Burden`, and assign the resulting table to `berkeley_ft`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "berkeley = ...\n",
    "berkeley_ft = ...\n",
    "berkeley_ft.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Pesticides</th>\n",
       "      <th>Groundwater Threats</th>\n",
       "      <th>Pollution Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>6001422000</td>\n",
       "      <td>94710</td>\n",
       "      <td>39.951350</td>\n",
       "      <td>8.8</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.00</td>\n",
       "      <td>58.519327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2361</th>\n",
       "      <td>6001423200</td>\n",
       "      <td>94710</td>\n",
       "      <td>36.091186</td>\n",
       "      <td>22.9</td>\n",
       "      <td>42.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.55</td>\n",
       "      <td>44.962177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3129</th>\n",
       "      <td>6001424002</td>\n",
       "      <td>94702</td>\n",
       "      <td>30.552611</td>\n",
       "      <td>23.7</td>\n",
       "      <td>37.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.30</td>\n",
       "      <td>44.040946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>6001422100</td>\n",
       "      <td>94710</td>\n",
       "      <td>29.538834</td>\n",
       "      <td>24.8</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.80</td>\n",
       "      <td>46.131570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>6001423100</td>\n",
       "      <td>94702</td>\n",
       "      <td>27.744060</td>\n",
       "      <td>23.0</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.50</td>\n",
       "      <td>42.770954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3659</th>\n",
       "      <td>6001422200</td>\n",
       "      <td>94702</td>\n",
       "      <td>26.966131</td>\n",
       "      <td>20.6</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.80</td>\n",
       "      <td>40.264766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4081</th>\n",
       "      <td>6001423300</td>\n",
       "      <td>94702</td>\n",
       "      <td>24.346142</td>\n",
       "      <td>19.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55.10</td>\n",
       "      <td>44.664415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4127</th>\n",
       "      <td>6001423400</td>\n",
       "      <td>94703</td>\n",
       "      <td>24.135257</td>\n",
       "      <td>23.8</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.80</td>\n",
       "      <td>37.471131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4247</th>\n",
       "      <td>6001420400</td>\n",
       "      <td>94710</td>\n",
       "      <td>23.522346</td>\n",
       "      <td>43.7</td>\n",
       "      <td>51.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.65</td>\n",
       "      <td>50.732530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>6001422900</td>\n",
       "      <td>94704</td>\n",
       "      <td>22.377374</td>\n",
       "      <td>38.1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.75</td>\n",
       "      <td>34.815446</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Census Tract    ZIP  CES 3.0 Score  Housing Burden  Poverty  Pesticides  \\\n",
       "1905    6001422000  94710      39.951350             8.8     41.5         0.0   \n",
       "2361    6001423200  94710      36.091186            22.9     42.3         0.0   \n",
       "3129    6001424002  94702      30.552611            23.7     37.1         0.0   \n",
       "3288    6001422100  94710      29.538834            24.8     27.5         0.0   \n",
       "3536    6001423100  94702      27.744060            23.0     30.5         0.0   \n",
       "3659    6001422200  94702      26.966131            20.6     27.0         0.0   \n",
       "4081    6001423300  94702      24.346142            19.5     28.6         0.0   \n",
       "4127    6001423400  94703      24.135257            23.8     30.5         0.0   \n",
       "4247    6001420400  94710      23.522346            43.7     51.2         0.0   \n",
       "4456    6001422900  94704      22.377374            38.1     63.1         0.0   \n",
       "\n",
       "      Groundwater Threats  Pollution Burden  \n",
       "1905               236.00         58.519327  \n",
       "2361                56.55         44.962177  \n",
       "3129                49.30         44.040946  \n",
       "3288                70.80         46.131570  \n",
       "3536                33.50         42.770954  \n",
       "3659                33.80         40.264766  \n",
       "4081                55.10         44.664415  \n",
       "4127                17.80         37.471131  \n",
       "4247                39.65         50.732530  \n",
       "4456                24.75         34.815446  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "berkeley = df0[df0['City'] == 'Berkeley'].dropna()\n",
    "berkeley_ft = berkeley[['Census Tract', 'ZIP', 'CES 3.0 Score', 'Housing Burden', 'Poverty', \n",
    "                        'Pesticides', 'Groundwater Threats', 'Pollution Burden']]\n",
    "berkeley_ft.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEIGI, I'M NOT FINDING THIS DISCUSSION TO BE CLEAR.  ALSO IT SHOULD BE MADE CLEAR (I THINK) THAT THE QUESTION IS NOT TO BE ANSWERED, IT'S JUST A THOUGHT.  SHOULD STUDENTS DESCRIBE WHAT THE COLUMNS MEAN.  ALSO SHOULD WE HAVE THEM DESCRIBE THE ORIGINS OF THE DATA. Are these values expected or slightly surprising? If we were working with percentiles, it would give us a better idea of how impacted (or not) a specific community is compared to the rest of the tracts in California. We can plot these values in a histogram later to evaluate how \"high\" or \"low\" a value is compared to the rest.\n",
    "\n",
    "Let's compare the two rows in our table -- specifically the rows with Census Tract `6001421100` and `06001422000`. Run the following cell to load the two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Pesticides</th>\n",
       "      <th>Groundwater Threats</th>\n",
       "      <th>Pollution Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7920</th>\n",
       "      <td>6001421100</td>\n",
       "      <td>94708</td>\n",
       "      <td>1.473015</td>\n",
       "      <td>11.7</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.788499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>6001422000</td>\n",
       "      <td>94710</td>\n",
       "      <td>39.951350</td>\n",
       "      <td>8.8</td>\n",
       "      <td>41.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>58.519327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Census Tract    ZIP  CES 3.0 Score  Housing Burden  Poverty  Pesticides  \\\n",
       "7920    6001421100  94708       1.473015            11.7      7.9         0.0   \n",
       "1905    6001422000  94710      39.951350             8.8     41.5         0.0   \n",
       "\n",
       "      Groundwater Threats  Pollution Burden  \n",
       "7920                  0.0         15.788499  \n",
       "1905                236.0         58.519327  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind1 = berkeley_ft[berkeley_ft['Census Tract'] == 6001421100.0]\n",
    "ind2 = berkeley_ft[berkeley_ft['Census Tract'] == 6001422000.0]\n",
    "ind1.append(ind2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two communities are extremely different -- one has an extremely low score and one has a high score, and the values in the features are also pretty varied. Let's take a look at where their scores lie in various histograms of the features.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 1.5:</b> Plot a distribution for the `Poverty` variable of all Berkeley tracts as well as for `Pollution Burden`. Along with these histograms, plot the points in which these two tracts lie within the distribution.\n",
    "\n",
    "Hint: Use `plt.scatter` for the individual points.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION (poverty hist)\n",
    "plt.hist(berkeley_ft['Poverty'], bins=np.arange(0, 71, 7))\n",
    "plt.scatter(ind1['Poverty'].values, y=0, c='r', s=30)\n",
    "plt.scatter(ind2['Poverty'].values, y=0, c='y', s=30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAD1CAYAAAB+8aORAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAADR9JREFUeJzt3V2MXPdZgPHntbfR1nEy2w+KIseVk2rVD1U0reKS4FVlkoJCcOyLtFJQg4qFxAUFXNSqSpBQBFIUcVOSC4SE0hqkhhbjpqWyrLZRGgv2AmPygfLhRlPSNLHT1kHEmwiThqUvF3O8NbblnX1nj+djn59keebs7Oz7957xs3Nmd09kJpIkrdS6YQ8gSRpPBkSSVGJAJEklBkSSVGJAJEklU4PewcLCgt/GJUkTrtPpxNnbfAYiSSoxIJKkkpEJSLfbHfYIrXONk8E1TgbXOLiRCYgkabwYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUM/KtMpLVm6/wGmD8+7DE4uXvTsEfQGuczEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSSV8BiYg/jIinI+KpiPhyREy3PZgkabQtG5CI2AT8AXBtZr4fWA/c1vZgkqTR1u8hrCngzRExBWwAXmpvJEnSOIjMXP5GEXuAu4H/Br6dmZ84/baFhYWlO+h2u23MKAGwdX7DsEcYKUfmTg17BE242dnZpcudTifOfvvUcncQEW8BdgFXASeBv4+I2zPzSxf6YCvV7XYHev9x4BoHNH+8nfsdU23uS+6rk6HtNfZzCOujwPcz8+XM/B/gQeCXWptIkjQW+gnIC8B1EbEhIgK4ETja7liSpFG3bEAy8zCwH3gMeLJ5n79qeS5J0ohb9jUQgMy8C7ir5VkkSWPEn0SXJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSSV8BiYiZiNgfEd+NiKMRcX3bg0mSRttUn7e7D/hmZn4sIi4BNrQ4kyRpDCwbkIi4HPgI8FsAmfkG8Ea7Y0mSRl0/h7CuBl4G9kbE4xFxf0Rc2vJckqQRF5l54RtEXAv8M7AtMw9HxH3Aq5n5xwALCwtLd9DtdtucVWvc1nmPnJ7pyNypYY+gCTc7O7t0udPpxNlv7+c1kGPAscw83FzfD9yx3AdbqW63O9D7jwPXOKD54+3c75hqc19yX50Mba9x2UNYmfkj4MWIeHez6UbgmdYmkiSNhX6/C+v3gQea78B6Dtjd3kiSpHHQV0Ay8wng2pZnkSSNEX8SXZJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSX9npFQks5rZu9onKv+5O5Nwx5hzfEZiCSpxIBIkkoMiCSpxIBIkkoMiCSpxIBIkkoMiCSpxIBIkkoMiCSpxIBIkkoMiCSpxIBIkkoMiCSpxIBIkkoMiCSpxIBIkkoMiCSppO+ARMT6iHg8Ig60OZAkaTys5BnIHuBoW4NIksZLXwGJiCuBXwfub3ccSdK46PcZyL3A54CftjiLJGmMRGZe+AYRO4CbM/N3I2I78NnM3HH67QsLC0t30O1225pTYuv8hmGPoBF2ZO7UsEeYOLOzs0uXO51OnP32qT7uYxuwMyJuBqaByyPiS5l5+4U+2Ep1u92B3n8cuMYBzR9v5341EVa63/l4HNyyh7Ay887MvDIztwC3Ad85XzwkSWuLPwciSSrp5xDWksw8BBxqZRJJ0ljxGYgkqcSASJJKDIgkqcSASJJKDIgkqcSASJJKDIgkqcSASJJKDIgkqcSASJJKDIgkqcSASJJKDIgkqcSASJJKDIgkqcSASJJKDIgkqWRFZyTUxTOz9/iwR1hycvemYY8gaQT5DESSVGJAJEklBkSSVGJAJEklBkSSVGJAJEklBkSSVGJAJEklBkSSVGJAJEklBkSSVGJAJEklBkSSVGJAJEklBkSSVGJAJEklBkSSVLJsQCJic0Q8EhFHI+LpiNhzMQaTJI22fk5puwh8JjMfi4jLgEcj4qHMfKbl2SRJI2zZZyCZ+cPMfKy5/BpwFPAk2ZK0xkVm9n/jiC3APwLvz8xXARYWFpbuoNvtrvJ4a9fW+Q3DHmHJkblTwx4BGK1/E42eUdlPJ8ns7OzS5U6nE2e/vZ9DWABExEbgq8CnT8fjQh9spbrd7kDvPw5WtMb54+0OswIr+by0+nkcoX8TjZ6V7nf+nzO4vr4LKyLeRC8eD2Tmg61NI0kaG/18F1YAXwCOZubn2x9JkjQO+nkGsg34TeCGiHii+XNzy3NJkkbcsq+BZOY8cM6LJ5Kktc2fRJcklRgQSVKJAZEklRgQSVKJAZEklRgQSVKJAZEklRgQSVKJAZEklRgQSVKJAZEklRgQSVKJAZEklRgQSVKJAZEklRgQSVLJsieUkmb2Hl/BrTfA/EpuL62Ole2nsBb21SNz7d6/z0AkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSUGRJJUYkAkSSV9BSQiboqIZyPiexFxR9tDSZJG37IBiYj1wF8Avwa8D/iNiHhf24NJkkZbP89APgx8LzOfy8w3gK8Au9odS5I06voJyCbgxTOuH2u2SZLWsKk+bhPn2Zbnu2G32x1omEHffxz0u8Yjc6v3Md95zz2848EHz9l+4tZbeeEOX9KSxsXrr9/D4uK5j+WpqVuZnj7/Y3mQ/1dnZ2cv+PZ+AnIM2HzG9SuBlyof7EK63e5A7z8OhrXGqV27yIMHiddfX9qW09NcumvXqs/j53EyuMbR9Moru/jBDw6S+bPHcsQ0mzfvYmbm3LW0vcZ+DmEdAWYj4qqIuAS4DfhGaxNp1S3ecguLc3Pk9DTQi8fi3ByLO3YMeTJJKzEzcwsbN84R0XssR0yzceMcnc5wHsvLPgPJzMWI+D3gW8B64IuZ+XTrk2n1rFvHqX37mDpwgKlDh1jcvr0Xj3X+GJA0TiLW8a537WNh4QCvvXaIyy7bTqezg4jhPJb7OYRFZh4EDrY8i9q0bh2LO3eyuHPnsCeRNICIdczM7GRmZviPZb8ElSSVGBBJUokBkSSVGBBJUokBkSSVGBBJUklknve3kvRtYWFhsDuQJI28Tqdzzq+18hmIJKnEgEiSSgY+hCVJWpt8BiJJKhmJgEziOdcj4osRcSIinjpj21sj4qGI6DZ/v2WYMw4iIjZHxCMRcTQino6IPc32SVrjdET8S0T8W7PGP2m2XxURh5s1/l3zW6rHWkSsj4jHI+JAc32i1hgRz0fEkxHxRET8a7NtYvZVgIiYiYj9EfHd5nF5fdtrHHpAJvic638N3HTWtjuAhzNzFni4uT6uFoHPZOZ7geuATzWft0la40+AGzLzA8A1wE0RcR3wZ8CfN2t8BfjtIc64WvYAR8+4Polr/OXMvCYzr22uT9K+CnAf8M3MfA/wAXqfz3bXmJlD/QNcD3zrjOt3AncOe65VWtsW4Kkzrj8LXNFcvgJ4dtgzruJa/wH4lUldI7ABeAz4ReA/gKlm+//bf8fxD72TxD0M3AAcoHcW0klb4/PA28/aNjH7KnA58H2a17Uv1hqH/gyEtXXO9Z/PzB8CNH+/Y8jzrIqI2AJ8EDjMhK2xObTzBHACeAj4d+BkZi42N5mE/fVe4HPAT5vrb2Py1pjAtyPi0Yj4nWbbJO2rVwMvA3ubQ5H3R8SltLzGUQhI3+dc1+iJiI3AV4FPZ+arw55ntWXm/2bmNfS+Sv8w8N7z3eziTrV6ImIHcCIzHz1z83luOrZrbGzLzA/RO1T+qYj4yLAHWmVTwIeAv8zMDwL/xUU4JDcKAen7nOsT4McRcQVA8/eJIc8zkIh4E714PJCZDzabJ2qNp2XmSeAQvdd7ZiLi9MnYxn1/3QbsjIjnga/QO4x1L5O1RjLzpebvE8DX6H0xMEn76jHgWGYebq7vpxeUVtc4CgFZS+dc/wbwyebyJ+m9bjCWIiKALwBHM/PzZ7xpktb4cxEx01x+M/BRei9MPgJ8rLnZWK8xM+/MzCszcwu9x953MvMTTNAaI+LSiLjs9GXgV4GnmKB9NTN/BLwYEe9uNt0IPEPLaxyJHySMiJvpfdVz+pzrdw95pIFFxJeB7cDbgR8DdwFfB/YB7wReAD6emf85rBkHERFzwD8BT/KzY+d/RO91kElZ4y8Af0Nvv1wH7MvMP42Iq+l9tf5W4HHg9sz8yfAmXR0RsR34bGbumKQ1Nmv5WnN1CvjbzLw7It7GhOyrABFxDXA/cAnwHLCbZr+lpTWOREAkSeNnFA5hSZLGkAGRJJUYEElSiQGRJJUYEElSiQGRJJUYEElSiQGRJJX8Hxtfc5+gD8IiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SOLUTION (pollution burden hist)\n",
    "plt.hist(berkeley_ft['Pollution Burden'], bins=np.arange(0, 61, 6))\n",
    "plt.scatter(ind1['Pollution Burden'].values, y=0, c='r', s=30)\n",
    "plt.scatter(ind2['Pollution Burden'].values, y=0, c='y', s=30);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, let's take a look at the demographic profiles of these two communities. This data is stored in the `Demographic profile` sheet.\n",
    "\n",
    "<div class = \"alert alert-warning\">\n",
    "\n",
    "<b>Question 1.6:</b> Similar to what we did earlier by comparing the two rows, compare the two tracts' demographic information (i.e. display the two rows together). We've loaded the sheet into a dataframe `dp` and have renamed the columns for you.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = xl.parse('Demographic profile')\n",
    "dp = dp.rename(columns = {'Census Tract ': 'Census Tract',\n",
    "                          'Age group from 2010 Census (%)':'Children < 10 (%)', \n",
    "                          'Unnamed: 7':'Pop 11-64 years (%)',\n",
    "                          'Unnamed: 8':'Elderly > 65 (%)', \n",
    "                          'Race or ethnicity from 2010 Census (%)':'Hispanic (%)',\n",
    "                          'Unnamed: 10':'White (%)',\n",
    "                          'Unnamed: 11':'African American (%)', \n",
    "                          'Unnamed: 12': 'Native American (%)', \n",
    "                          'Unnamed: 13':'Asian American (%)', \n",
    "                          'Unnamed: 14': 'Other (%)'})\n",
    "\n",
    "# YOUR CODE HERE\n",
    "demo1 = ...\n",
    "demo2 = ...\n",
    "demo1.append(demo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>CES 3.0 Percentile</th>\n",
       "      <th>CES 3.0 \n",
       "Percentile Range</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>California \n",
       "County</th>\n",
       "      <th>Children &lt; 10 (%)</th>\n",
       "      <th>Pop 11-64 years (%)</th>\n",
       "      <th>Elderly &gt; 65 (%)</th>\n",
       "      <th>Hispanic (%)</th>\n",
       "      <th>White (%)</th>\n",
       "      <th>African American (%)</th>\n",
       "      <th>Native American (%)</th>\n",
       "      <th>Asian American (%)</th>\n",
       "      <th>Other (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7921</th>\n",
       "      <td>6.001421e+09</td>\n",
       "      <td>1.473015</td>\n",
       "      <td>0.113507</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>9.5</td>\n",
       "      <td>63.3</td>\n",
       "      <td>27.2</td>\n",
       "      <td>5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1906</th>\n",
       "      <td>6.001422e+09</td>\n",
       "      <td>39.951350</td>\n",
       "      <td>75.974272</td>\n",
       "      <td>76-80%</td>\n",
       "      <td>1756.0</td>\n",
       "      <td>Alameda</td>\n",
       "      <td>9.1</td>\n",
       "      <td>82.5</td>\n",
       "      <td>8.4</td>\n",
       "      <td>12.6</td>\n",
       "      <td>43.3</td>\n",
       "      <td>28</td>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>5.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Census Tract   CES 3.0 Score  CES 3.0 Percentile  \\\n",
       "7921  6.001421e+09        1.473015            0.113507   \n",
       "1906  6.001422e+09       39.951350           75.974272   \n",
       "\n",
       "      CES 3.0 \\nPercentile Range  Total Population California \\nCounty  \\\n",
       "7921        1-5% (lowest scores)            1992.0            Alameda    \n",
       "1906                      76-80%            1756.0            Alameda    \n",
       "\n",
       "     Children < 10 (%) Pop 11-64 years (%) Elderly > 65 (%) Hispanic (%)  \\\n",
       "7921               9.5                63.3             27.2            5   \n",
       "1906               9.1                82.5              8.4         12.6   \n",
       "\n",
       "     White (%) African American (%) Native American (%) Asian American (%)  \\\n",
       "7921      76.5                  1.8                   0                 12   \n",
       "1906      43.3                   28                 0.2                 10   \n",
       "\n",
       "     Other (%)  \n",
       "7921       4.6  \n",
       "1906       5.9  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "dp = xl.parse('Demographic profile')\n",
    "dp = dp.rename(columns = {'Census Tract ': 'Census Tract',\n",
    "                          'Age group from 2010 Census (%)':'Children < 10 (%)', \n",
    "                          'Unnamed: 7':'Pop 11-64 years (%)',\n",
    "                          'Unnamed: 8':'Elderly > 65 (%)', \n",
    "                          'Race or ethnicity from 2010 Census (%)':'Hispanic (%)',\n",
    "                          'Unnamed: 10':'White (%)',\n",
    "                          'Unnamed: 11':'African American (%)', \n",
    "                          'Unnamed: 12': 'Native American (%)', \n",
    "                          'Unnamed: 13':'Asian American (%)', \n",
    "                          'Unnamed: 14': 'Other (%)'})\n",
    "\n",
    "demo1 = dp[dp['Census Tract'] == 6001421100.0]\n",
    "demo2 = dp[dp['Census Tract'] == 6001422000.0]\n",
    "demo1.append(demo2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're curious, you can take a look at where these census tracts are located by inputting the coordinates in [maps](https://www.google.com/maps).\n",
    "- Coordinates for the first row: (+37.8994340, -122.2661928)\n",
    "- Coordinates for second row: (+37.8590327, -122.3013426)\n",
    "\n",
    "You can then find the tract areas by using this [web tool](https://data.cityofberkeley.info/Demographics/Census-Tract-Polygons-2010/peq3-2arw) provided by the city of Berkeley!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 2. A Decision Tree From Scratch <a name = 'scratch'></a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by creating a decision tree from scratch! Even though trees are pretty easy to interpret, there's a lot that runs to create the final tree. We'll walk through creating a tree which will hopefully help our intuition when we use scikit-learn later in this homework.\n",
    "\n",
    "First, let's take a very small subset of our data so that our tree will be easy to work with. There are a few things we're doing here to make this process more digestible -- we're taking a sample of 10 from the table and we are classifying the top and bottom groups of the CES dataset.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "SEIGI, I'M NOT FINDING THIS QUESTION TO BE CLEAR<b>Question 2.1:</b> In the following cell, we've loaded the first sheet of the excel file into a dataframe called `data`. Find the indices of the group with the highest scores and the lowest scores as well, assigning them to the variables `top` and `bottom` respectively. Then, fill out the ellipses in the `sample` method  -- we want to take a sample of 10, and set the random_state to 1.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundwater Threats</th>\n",
       "      <th>Drinking Water</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7672</th>\n",
       "      <td>0.00</td>\n",
       "      <td>204.133310</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7541</th>\n",
       "      <td>1.50</td>\n",
       "      <td>70.599583</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24.00</td>\n",
       "      <td>681.195604</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>4.00</td>\n",
       "      <td>664.069078</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>5.00</td>\n",
       "      <td>67.043782</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>4.25</td>\n",
       "      <td>644.868868</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>15.00</td>\n",
       "      <td>495.257331</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>0.00</td>\n",
       "      <td>437.425659</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>6.00</td>\n",
       "      <td>835.976652</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.75</td>\n",
       "      <td>557.338833</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Groundwater Threats  Drinking Water  CES 3.0 Percentile Range\n",
       "7672                 0.00      204.133310      1-5% (lowest scores)\n",
       "7541                 1.50       70.599583      1-5% (lowest scores)\n",
       "19                  24.00      681.195604  96-100% (highest scores)\n",
       "223                  4.00      664.069078  96-100% (highest scores)\n",
       "7535                 5.00       67.043782      1-5% (lowest scores)\n",
       "279                  4.25      644.868868  96-100% (highest scores)\n",
       "203                 15.00      495.257331  96-100% (highest scores)\n",
       "7586                 0.00      437.425659      1-5% (lowest scores)\n",
       "285                  6.00      835.976652  96-100% (highest scores)\n",
       "383                  0.75      557.338833  96-100% (highest scores)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data = df0.rename(columns={'CES 3.0 \\nPercentile Range':'CES 3.0 Percentile Range'})\n",
    "\n",
    "...\n",
    "...\n",
    "\n",
    "scratch = data.iloc[top.append(bottom)].dropna()\n",
    "scratch = scratch[[\"Groundwater Threats\", \n",
    "                   \"Drinking Water\",           # YOUR CODE HERE\n",
    "                   \"CES 3.0 Percentile Range\"]].sample(...)\n",
    "scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Groundwater Threats</th>\n",
       "      <th>Drinking Water</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7672</th>\n",
       "      <td>0.00</td>\n",
       "      <td>204.133310</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7541</th>\n",
       "      <td>1.50</td>\n",
       "      <td>70.599583</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>24.00</td>\n",
       "      <td>681.195604</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>4.00</td>\n",
       "      <td>664.069078</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7535</th>\n",
       "      <td>5.00</td>\n",
       "      <td>67.043782</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>4.25</td>\n",
       "      <td>644.868868</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>15.00</td>\n",
       "      <td>495.257331</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7586</th>\n",
       "      <td>0.00</td>\n",
       "      <td>437.425659</td>\n",
       "      <td>1-5% (lowest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>6.00</td>\n",
       "      <td>835.976652</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.75</td>\n",
       "      <td>557.338833</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Groundwater Threats  Drinking Water  CES 3.0 Percentile Range\n",
       "7672                 0.00      204.133310      1-5% (lowest scores)\n",
       "7541                 1.50       70.599583      1-5% (lowest scores)\n",
       "19                  24.00      681.195604  96-100% (highest scores)\n",
       "223                  4.00      664.069078  96-100% (highest scores)\n",
       "7535                 5.00       67.043782      1-5% (lowest scores)\n",
       "279                  4.25      644.868868  96-100% (highest scores)\n",
       "203                 15.00      495.257331  96-100% (highest scores)\n",
       "7586                 0.00      437.425659      1-5% (lowest scores)\n",
       "285                  6.00      835.976652  96-100% (highest scores)\n",
       "383                  0.75      557.338833  96-100% (highest scores)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "data = df0.rename(columns={'CES 3.0 \\nPercentile Range':'CES 3.0 Percentile Range'})\n",
    "\n",
    "top = data[data['CES 3.0 Percentile Range'] == '96-100% (highest scores)'].index\n",
    "bottom = data[data['CES 3.0 Percentile Range'] == '1-5% (lowest scores)'].index\n",
    "\n",
    "scratch = data.iloc[top.append(bottom)]\n",
    "scratch = scratch.dropna().loc[:,[\"Groundwater Threats\", \"Drinking Water\", \n",
    "                                \"CES 3.0 Percentile Range\"]].sample(10, random_state=1)\n",
    "scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SEIGI, NOT CLEAR: The first the we want to do when we building a tree is how can we create each split in the tree. To do so, we'll start with calculating the gini index. The optimal split for any given feature is determined by a cost function that defines purity. The gini index quantifies a split by the class composition of the resulting two groups where a low score means a near perfect split and a high score means the composition is nearly the same in both groups. The gini index is calculated as follows:\n",
    "\n",
    "SEIGI, I ONLY HAD A SECOND TO LOOK AT THIS BUT I THINK THE FORMULA IS WRONG (AFTER THE SECOND EQUALS SIGN, $1-p_k^2$) AND THE ERROR SPILLS OVER INTO THE CODE.  \n",
    "$$ G = \\sum_{k = 1}^{K}{\\hat{p}_k(1 - \\hat{p}_k)} = \\sum_{k = 1}^{K} (1 - \\hat{p}^2_k)$$\n",
    "\n",
    "where $G$ is the Gini index, and $\\hat{p}_k$ is the proportion of count in each variable in the training set.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 2.2:</b> Take a look at the following cell, which contains the code in order to calculate the gini index. There are letters following three pound symbols. Write down what the line below is doing for each letter.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini_index(groups, classes):\n",
    "    ### A ###\n",
    "    n_instances = float(sum([len(group) for group in groups]))\n",
    "    ### B ###\n",
    "    gini = 0.0\n",
    "    for group in groups:\n",
    "        size = float(len(group))\n",
    "        if size == 0:\n",
    "            continue\n",
    "        score = 0.0\n",
    "        ### C ###\n",
    "        for class_val in classes:\n",
    "            p = [row[-1] for row in group].count(class_val) / size\n",
    "            score += p * p\n",
    "        ### D ###\n",
    "        gini += (1.0 - score) * (size / n_instances)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWERS HERE***\n",
    "\n",
    "**A)**\n",
    "\n",
    "**B)**\n",
    "\n",
    "**C)**\n",
    "\n",
    "**D)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***solution***\n",
    "- a) count samples at split point\n",
    "- b) sum weighted Gini index for each group\n",
    "- c) score the group based on the score for each class\n",
    "- d) weight the group score by its relative size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "Now, we can look at creating a split. A split is comprised of an attribute in the dataset and a value and creating one involves three parts.\n",
    "\n",
    "1. Calculating the gini index\n",
    "2. Splitting a dataset\n",
    "3. Evaluating all splits\n",
    "\n",
    "We'll look at the second step now!\n",
    "\n",
    "Splitting a dataset means separating a dataset into two lists of rows given the index of an attribute and a split value for that attribute. Once we have the two groups, we can use the gini index above to evaluate the cost of the split. In this procedure, we iterate over each row to check if the attribute value is below or above the split value and then we'll assign it to the left or right group respectively.\n",
    "\n",
    "Run the following cell to load the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(index, value, dataset):\n",
    "    left, right = list(), list()\n",
    "    for row in dataset:\n",
    "        if row[index] < value:\n",
    "            left.append(row)\n",
    "        else:\n",
    "            right.append(row)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 2.3:</b> What does the group sorted in the right list represent?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**:  the right group contains all rows with a value at the index above or equal to the split value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "We can create our splits now. Given a dataset, we must check every value on each attribute as a candidate split, evaluate the cost of the split and find the best possible split we could make. The lowest gini score across all the features would then be chosen as the best split and a node would be created.\n",
    "\n",
    "We will use a dictionary to represent a node in the decision tree as we can store data by name. When selecting the best split and using it as a new node for the tree we will store the index of the chosen attribute, the value of that attribute by which to split and the two groups of data split by the chosen split point.\n",
    "\n",
    "The function below runs this procedure. Run the cell to load function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(dataset):\n",
    "    class_values = list(set(row[-1] for row in dataset))\n",
    "    b_index, b_value, b_score, b_groups = 999, 999, 999, None\n",
    "    for index in range(len(dataset[0])-1):\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            gini = gini_index(groups, class_values)\n",
    "            if gini < b_score:\n",
    "                b_index = index\n",
    "                b_value = row[index]\n",
    "                b_score = gini\n",
    "                b_groups = groups\n",
    "    return {'index':b_index, 'value':b_value, 'groups':b_groups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all of the tools to find the best splits of the tree -- let's see how we can use them to *build* one from the ground up (or from the top since trees are inverted...). \n",
    "\n",
    "Building a tree takes two main steps: finding leaves (e.g. when to stop the tree) and recursively splitting the tree.\n",
    "\n",
    "The following cell contains the function that returns the most common output in a list of rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a terminal node value\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return max(set(outcomes), key=outcomes.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 2.4:</b> What is a problem when fitting a tree too deeply? What about having too many nodes?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We're almost there! The following cell contains the function that performs the recursive splitting. \n",
    "\n",
    "Here are the steps of this procedure:\n",
    "\n",
    "1. Two groups of data split by the node are extracted and deleted from the node. The node no longer requires access to these data when we work on the node.\n",
    "2. We check if either left or right group of rows is empty and if so we create a terminal node using the data and computed scores we have.\n",
    "3. Check if we have reached our maximum depth. If we have, create a terminal node.\n",
    "4. If the group of rows is too small, we process the left child and create a terminal node. Otherwise, we create and add the left node in a depth-first fashion until the bottom of the tree is reached on this branch.\n",
    "5. Right side is then processed in the same manner, as we rise back up the constructed tree to the root.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 2.5:</b> Similar to question 2.2, look at the following cell and note what each control case is doing in the `split` function.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(node, max_depth, min_size, depth):\n",
    "    left, right = node['groups']\n",
    "    del(node['groups'])\n",
    "    ### A ###\n",
    "    if not left or not right:\n",
    "        node['left'] = node['right'] = to_terminal(left + right)\n",
    "        return\n",
    "    ### B ###\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "    ### C ###\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left)\n",
    "        split(node['left'], max_depth, min_size, depth+1)\n",
    "    ### D ###\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right)\n",
    "        split(node['right'], max_depth, min_size, depth+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***\n",
    "\n",
    "**A)**\n",
    "\n",
    "**B)**\n",
    "\n",
    "**C)**\n",
    "\n",
    "**D)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**\n",
    "- a. check for an empty split\n",
    "- b. check for max depth\n",
    "- c. process left child\n",
    "- d. process right child"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Awesome! We're ready to build our tree. In the following cell, we have our `build_tree` and `print_tree` function. Most of the steps were abstracted away in `get_split` and `split` functions. Before we use the function, we can't directly use a pandas dataframe or series as input to this function.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 2.6:</b> In the same cell, assign a list of the rows of the dataframe to the variable `rows`. Run the cell and see the resulting tree. What do the inqualities represent? How does it relate to the data we inputted into the tree?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "# YOUR CODE HERE       \n",
    "rows = ...\n",
    "scratch_tree = build_tree(rows, 2, 2)\n",
    "print_tree(scratch_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[X2 < 495.257]\n",
      " [X1 < 0.000]\n",
      "  [1-5% (lowest scores)]\n",
      "  [1-5% (lowest scores)]\n",
      " [X1 < 24.000]\n",
      "  [96-100% (highest scores)]\n",
      "  [96-100% (highest scores)]\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "def build_tree(train, max_depth, min_size):\n",
    "    root = get_split(train)\n",
    "    split(root, max_depth, min_size, 1)\n",
    "    return root\n",
    "\n",
    "def print_tree(node, depth=0):\n",
    "    if isinstance(node, dict):\n",
    "        print('%s[X%d < %.3f]' % ((depth*' ', (node['index']+1), node['value'])))\n",
    "        print_tree(node['left'], depth+1)\n",
    "        print_tree(node['right'], depth+1)\n",
    "    else:\n",
    "        print('%s[%s]' % ((depth*' ', node)))\n",
    "\n",
    "# YOUR CODE HERE       \n",
    "rows = [scratch.iloc[i].values for i in range(scratch.shape[0])]\n",
    "scratch_tree = build_tree(rows, 2, 2)\n",
    "print_tree(scratch_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "Just for fun, we can also use this tree for prediction (although we really shouldn't since we used the full ten samples to fit the tree). Run the following cell to see the expected and predicted values from our dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  96-100% (highest scores)\n",
      "Got:  96-100% (highest scores) \n",
      "\n",
      "Expected:  96-100% (highest scores)\n",
      "Got:  96-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  96-100% (highest scores)\n",
      "Got:  96-100% (highest scores) \n",
      "\n",
      "Expected:  96-100% (highest scores)\n",
      "Got:  96-100% (highest scores) \n",
      "\n",
      "Expected:  1-5% (lowest scores)\n",
      "Got:  1-5% (lowest scores) \n",
      "\n",
      "Expected:  96-100% (highest scores)\n",
      "Got:  96-100% (highest scores) \n",
      "\n",
      "Expected:  96-100% (highest scores)\n",
      "Got:  96-100% (highest scores) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def predict(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "for row in rows:\n",
    "    prediction = predict(scratch_tree, row)\n",
    "    print('Expected: ', row[-1])\n",
    "    print('Got: ', prediction, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a better idea of how a tree works under the hood, let's move on to scikit-learn and create a more complex tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Implementing with Scikit-Learn <a name = 'sk'></a>\n",
    "\n",
    "Since our data has quite the amount of features, creating and tuning a tree from scratch would be a hassle and would not necessarily lead to optimal results. Here's where scikit-learn comes in and streamlines the process for us.\n",
    "\n",
    "We'll be using scikit-learn's `DecisionTreeClassifier` ([documenation](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)) in this section and use a larger subset of the data to create a more complex model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>California County</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>City</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>CES 3.0 Percentile</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "      <th>...</th>\n",
       "      <th>Linguistic Isolation Pctl</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Poverty Pctl</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Unemployment Pctl</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Housing Burden Pctl</th>\n",
       "      <th>Pop. Char.</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>Pop. Char. Pctl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6019001100</td>\n",
       "      <td>3174</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.781696</td>\n",
       "      <td>36.709695</td>\n",
       "      <td>94.089387</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>77.509665</td>\n",
       "      <td>76.3</td>\n",
       "      <td>97.121307</td>\n",
       "      <td>17.6</td>\n",
       "      <td>91.724838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.398324</td>\n",
       "      <td>92.120494</td>\n",
       "      <td>9.553440</td>\n",
       "      <td>99.697314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6071001600</td>\n",
       "      <td>6133</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>91761</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-117.618013</td>\n",
       "      <td>34.057780</td>\n",
       "      <td>90.677825</td>\n",
       "      <td>99.987388</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>96.253833</td>\n",
       "      <td>72.5</td>\n",
       "      <td>94.632307</td>\n",
       "      <td>12.3</td>\n",
       "      <td>71.823836</td>\n",
       "      <td>34.1</td>\n",
       "      <td>93.754760</td>\n",
       "      <td>87.436849</td>\n",
       "      <td>9.067783</td>\n",
       "      <td>98.108210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019000200</td>\n",
       "      <td>3167</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.805504</td>\n",
       "      <td>36.735491</td>\n",
       "      <td>85.968804</td>\n",
       "      <td>99.974776</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>78.389548</td>\n",
       "      <td>86.8</td>\n",
       "      <td>99.560025</td>\n",
       "      <td>16.1</td>\n",
       "      <td>87.980708</td>\n",
       "      <td>40.1</td>\n",
       "      <td>97.854785</td>\n",
       "      <td>94.581328</td>\n",
       "      <td>9.808662</td>\n",
       "      <td>99.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077000801</td>\n",
       "      <td>6692</td>\n",
       "      <td>San Joaquin</td>\n",
       "      <td>95203</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>-121.314524</td>\n",
       "      <td>37.940517</td>\n",
       "      <td>82.490978</td>\n",
       "      <td>99.962164</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>75.136648</td>\n",
       "      <td>61.3</td>\n",
       "      <td>85.568825</td>\n",
       "      <td>19.6</td>\n",
       "      <td>94.973981</td>\n",
       "      <td>21.1</td>\n",
       "      <td>63.544047</td>\n",
       "      <td>86.701266</td>\n",
       "      <td>8.991455</td>\n",
       "      <td>97.729852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6019001500</td>\n",
       "      <td>2206</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93725</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.717843</td>\n",
       "      <td>36.681600</td>\n",
       "      <td>82.030324</td>\n",
       "      <td>99.949552</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>73.723504</td>\n",
       "      <td>66.4</td>\n",
       "      <td>90.232558</td>\n",
       "      <td>18.6</td>\n",
       "      <td>93.654017</td>\n",
       "      <td>28.1</td>\n",
       "      <td>83.980706</td>\n",
       "      <td>80.075199</td>\n",
       "      <td>8.304296</td>\n",
       "      <td>92.773364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Census Tract  Total Population California County    ZIP      City  \\\n",
       "0    6019001100              3174           Fresno   93706    Fresno   \n",
       "1    6071001600              6133    San Bernardino  91761   Ontario   \n",
       "2    6019000200              3167           Fresno   93706    Fresno   \n",
       "3    6077000801              6692       San Joaquin  95203  Stockton   \n",
       "4    6019001500              2206           Fresno   93725    Fresno   \n",
       "\n",
       "    Longitude   Latitude  CES 3.0 Score   CES 3.0 Percentile  \\\n",
       "0 -119.781696  36.709695      94.089387           100.000000   \n",
       "1 -117.618013  34.057780      90.677825            99.987388   \n",
       "2 -119.805504  36.735491      85.968804            99.974776   \n",
       "3 -121.314524  37.940517      82.490978            99.962164   \n",
       "4 -119.717843  36.681600      82.030324            99.949552   \n",
       "\n",
       "   CES 3.0 Percentile Range       ...         Linguistic Isolation Pctl  \\\n",
       "0  96-100% (highest scores)       ...                         77.509665   \n",
       "1  96-100% (highest scores)       ...                         96.253833   \n",
       "2  96-100% (highest scores)       ...                         78.389548   \n",
       "3  96-100% (highest scores)       ...                         75.136648   \n",
       "4  96-100% (highest scores)       ...                         73.723504   \n",
       "\n",
       "   Poverty  Poverty Pctl  Unemployment  Unemployment Pctl  Housing Burden  \\\n",
       "0     76.3     97.121307          17.6          91.724838            26.0   \n",
       "1     72.5     94.632307          12.3          71.823836            34.1   \n",
       "2     86.8     99.560025          16.1          87.980708            40.1   \n",
       "3     61.3     85.568825          19.6          94.973981            21.1   \n",
       "4     66.4     90.232558          18.6          93.654017            28.1   \n",
       "\n",
       "   Housing Burden Pctl  Pop. Char.   Pop. Char. Score  Pop. Char. Pctl  \n",
       "0            79.398324    92.120494          9.553440        99.697314  \n",
       "1            93.754760    87.436849          9.067783        98.108210  \n",
       "2            97.854785    94.581328          9.808662        99.987388  \n",
       "3            63.544047    86.701266          8.991455        97.729852  \n",
       "4            83.980706    80.075199          8.304296        92.773364  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import tree\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 3.1. The First Tree\n",
    "\n",
    "For our first model, we'll use the features to predict which score bracket a certain tract lies in, namely we want to use these features to predict the `CES 3.0 Percentile Range`. For the sake of interpretability, we'll focus on the 91th percentile and above, and up to the 10th percentile of scores.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.1.1:</b> Before we move on, what is a problem that can stem from using such a specific subset of our data to build a classifier?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Your Answer Here***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the scores that have been binned already in the dataset so we know how to set up our model. Run the following cell to see them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['96-100% (highest scores)', '91-95%', '86-90%', '81-85%', '76-80%',\n",
       "       '71-75%', '66-70%', '61-65%', '56-60%', '51-55%', '46-50%',\n",
       "       '41-45%', '36-40%', '31-35%', '26-30%', '21-25%', '16-20%',\n",
       "       '11-15%', '6-10%', '1-5% (lowest scores)'], dtype=object)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CES 3.0 Percentile Range'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we have a total of four values that our tree can potentially classify if we want to take the top and bottom 10% of scores.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.1.2:</b> Get the index values for the data in the `96-100% (highest scores)` and `91-95%` range, and assign the values to the variable `pct90`. Do the same for `6-10%` and `1-5% (lowest scores)`, assigning the resulting values to the variable `pct10`.\n",
    "\n",
    "<br>\n",
    "\n",
    "Then, use `pct90` and `pct10` to get the resulting table and reassign it to `data`. This table should only contain the four ranges in the column `CES 3.0 Percentile Range`\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "print(pct90)\n",
    "\n",
    "...\n",
    "...\n",
    "...\n",
    "print(pct10)\n",
    "\n",
    "data = ...\n",
    "\n",
    "assert len(data['CES 3.0 Percentile Range'].unique()) == 4\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,\n",
      "            ...\n",
      "            783, 784, 785, 786, 787, 788, 789, 790, 791, 792],\n",
      "           dtype='int64', length=777)\n",
      "Int64Index([7532, 7533, 7535, 7536, 7537, 7538, 7539, 7540, 7541, 7542,\n",
      "            ...\n",
      "            7520, 7521, 7522, 7523, 7524, 7527, 7528, 7529, 7530, 7531],\n",
      "           dtype='int64', length=716)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Census Tract</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>California County</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>City</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>CES 3.0 Score</th>\n",
       "      <th>CES 3.0 Percentile</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "      <th>...</th>\n",
       "      <th>Linguistic Isolation Pctl</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Poverty Pctl</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Unemployment Pctl</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Housing Burden Pctl</th>\n",
       "      <th>Pop. Char.</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>Pop. Char. Pctl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6019001100</td>\n",
       "      <td>3174</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.781696</td>\n",
       "      <td>36.709695</td>\n",
       "      <td>94.089387</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>77.509665</td>\n",
       "      <td>76.3</td>\n",
       "      <td>97.121307</td>\n",
       "      <td>17.6</td>\n",
       "      <td>91.724838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.398324</td>\n",
       "      <td>92.120494</td>\n",
       "      <td>9.553440</td>\n",
       "      <td>99.697314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6071001600</td>\n",
       "      <td>6133</td>\n",
       "      <td>San Bernardino</td>\n",
       "      <td>91761</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>-117.618013</td>\n",
       "      <td>34.057780</td>\n",
       "      <td>90.677825</td>\n",
       "      <td>99.987388</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>96.253833</td>\n",
       "      <td>72.5</td>\n",
       "      <td>94.632307</td>\n",
       "      <td>12.3</td>\n",
       "      <td>71.823836</td>\n",
       "      <td>34.1</td>\n",
       "      <td>93.754760</td>\n",
       "      <td>87.436849</td>\n",
       "      <td>9.067783</td>\n",
       "      <td>98.108210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6019000200</td>\n",
       "      <td>3167</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93706</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.805504</td>\n",
       "      <td>36.735491</td>\n",
       "      <td>85.968804</td>\n",
       "      <td>99.974776</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>78.389548</td>\n",
       "      <td>86.8</td>\n",
       "      <td>99.560025</td>\n",
       "      <td>16.1</td>\n",
       "      <td>87.980708</td>\n",
       "      <td>40.1</td>\n",
       "      <td>97.854785</td>\n",
       "      <td>94.581328</td>\n",
       "      <td>9.808662</td>\n",
       "      <td>99.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6077000801</td>\n",
       "      <td>6692</td>\n",
       "      <td>San Joaquin</td>\n",
       "      <td>95203</td>\n",
       "      <td>Stockton</td>\n",
       "      <td>-121.314524</td>\n",
       "      <td>37.940517</td>\n",
       "      <td>82.490978</td>\n",
       "      <td>99.962164</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>75.136648</td>\n",
       "      <td>61.3</td>\n",
       "      <td>85.568825</td>\n",
       "      <td>19.6</td>\n",
       "      <td>94.973981</td>\n",
       "      <td>21.1</td>\n",
       "      <td>63.544047</td>\n",
       "      <td>86.701266</td>\n",
       "      <td>8.991455</td>\n",
       "      <td>97.729852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6019001500</td>\n",
       "      <td>2206</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>93725</td>\n",
       "      <td>Fresno</td>\n",
       "      <td>-119.717843</td>\n",
       "      <td>36.681600</td>\n",
       "      <td>82.030324</td>\n",
       "      <td>99.949552</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>...</td>\n",
       "      <td>73.723504</td>\n",
       "      <td>66.4</td>\n",
       "      <td>90.232558</td>\n",
       "      <td>18.6</td>\n",
       "      <td>93.654017</td>\n",
       "      <td>28.1</td>\n",
       "      <td>83.980706</td>\n",
       "      <td>80.075199</td>\n",
       "      <td>8.304296</td>\n",
       "      <td>92.773364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Census Tract  Total Population California County    ZIP      City  \\\n",
       "0    6019001100              3174           Fresno   93706    Fresno   \n",
       "1    6071001600              6133    San Bernardino  91761   Ontario   \n",
       "2    6019000200              3167           Fresno   93706    Fresno   \n",
       "3    6077000801              6692       San Joaquin  95203  Stockton   \n",
       "4    6019001500              2206           Fresno   93725    Fresno   \n",
       "\n",
       "    Longitude   Latitude  CES 3.0 Score   CES 3.0 Percentile  \\\n",
       "0 -119.781696  36.709695      94.089387           100.000000   \n",
       "1 -117.618013  34.057780      90.677825            99.987388   \n",
       "2 -119.805504  36.735491      85.968804            99.974776   \n",
       "3 -121.314524  37.940517      82.490978            99.962164   \n",
       "4 -119.717843  36.681600      82.030324            99.949552   \n",
       "\n",
       "   CES 3.0 Percentile Range       ...         Linguistic Isolation Pctl  \\\n",
       "0  96-100% (highest scores)       ...                         77.509665   \n",
       "1  96-100% (highest scores)       ...                         96.253833   \n",
       "2  96-100% (highest scores)       ...                         78.389548   \n",
       "3  96-100% (highest scores)       ...                         75.136648   \n",
       "4  96-100% (highest scores)       ...                         73.723504   \n",
       "\n",
       "   Poverty  Poverty Pctl  Unemployment  Unemployment Pctl  Housing Burden  \\\n",
       "0     76.3     97.121307          17.6          91.724838            26.0   \n",
       "1     72.5     94.632307          12.3          71.823836            34.1   \n",
       "2     86.8     99.560025          16.1          87.980708            40.1   \n",
       "3     61.3     85.568825          19.6          94.973981            21.1   \n",
       "4     66.4     90.232558          18.6          93.654017            28.1   \n",
       "\n",
       "   Housing Burden Pctl  Pop. Char.   Pop. Char. Score  Pop. Char. Pctl  \n",
       "0            79.398324    92.120494          9.553440        99.697314  \n",
       "1            93.754760    87.436849          9.067783        98.108210  \n",
       "2            97.854785    94.581328          9.808662        99.987388  \n",
       "3            63.544047    86.701266          8.991455        97.729852  \n",
       "4            83.980706    80.075199          8.304296        92.773364  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLUTION\n",
    "pct90 = data[data['CES 3.0 Percentile Range'] > '9'].index\n",
    "print(pct90)\n",
    "\n",
    "bottom = data[data['CES 3.0 Percentile Range'] == '1-5% (lowest scores)'].index\n",
    "bottom2 = data[data['CES 3.0 Percentile Range'] == '6-10%'].index\n",
    "pct10 = bottom.append(bottom2)\n",
    "print(pct10)\n",
    "\n",
    "data = data.loc[pct90.append(pct10)]\n",
    "\n",
    "assert len(data['CES 3.0 Percentile Range'].unique()) == 4\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our desired observations, let's filter through the certain features we want to use in our classification tree. Remember that a tree can use both continuous and categorical data, but we probably don't want to work with features like the county or zip code since it would clutter our data if we wanted to encode them. Run the following cell to drop the columns as well as the NaN values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Population</th>\n",
       "      <th>CES 3.0 Percentile Range</th>\n",
       "      <th>Ozone</th>\n",
       "      <th>Ozone Pctl</th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM2.5 Pctl</th>\n",
       "      <th>Diesel PM</th>\n",
       "      <th>Diesel PM Pctl</th>\n",
       "      <th>Drinking Water</th>\n",
       "      <th>Drinking Water Pctl</th>\n",
       "      <th>...</th>\n",
       "      <th>Linguistic Isolation Pctl</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Poverty Pctl</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Unemployment Pctl</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Housing Burden Pctl</th>\n",
       "      <th>Pop. Char.</th>\n",
       "      <th>Pop. Char. Score</th>\n",
       "      <th>Pop. Char. Pctl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3174</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>0.064889</td>\n",
       "      <td>98.182950</td>\n",
       "      <td>15.40</td>\n",
       "      <td>97.218064</td>\n",
       "      <td>48.523809</td>\n",
       "      <td>95.544493</td>\n",
       "      <td>681.195604</td>\n",
       "      <td>80.915554</td>\n",
       "      <td>...</td>\n",
       "      <td>77.509665</td>\n",
       "      <td>76.3</td>\n",
       "      <td>97.121307</td>\n",
       "      <td>17.6</td>\n",
       "      <td>91.724838</td>\n",
       "      <td>26.0</td>\n",
       "      <td>79.398324</td>\n",
       "      <td>92.120494</td>\n",
       "      <td>9.553440</td>\n",
       "      <td>99.697314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6133</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>0.062163</td>\n",
       "      <td>91.101431</td>\n",
       "      <td>13.31</td>\n",
       "      <td>93.637725</td>\n",
       "      <td>38.556339</td>\n",
       "      <td>92.121966</td>\n",
       "      <td>904.657603</td>\n",
       "      <td>96.108270</td>\n",
       "      <td>...</td>\n",
       "      <td>96.253833</td>\n",
       "      <td>72.5</td>\n",
       "      <td>94.632307</td>\n",
       "      <td>12.3</td>\n",
       "      <td>71.823836</td>\n",
       "      <td>34.1</td>\n",
       "      <td>93.754760</td>\n",
       "      <td>87.436849</td>\n",
       "      <td>9.067783</td>\n",
       "      <td>98.108210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3167</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>0.062163</td>\n",
       "      <td>91.101431</td>\n",
       "      <td>15.40</td>\n",
       "      <td>97.218064</td>\n",
       "      <td>47.445208</td>\n",
       "      <td>95.420037</td>\n",
       "      <td>681.195604</td>\n",
       "      <td>80.915554</td>\n",
       "      <td>...</td>\n",
       "      <td>78.389548</td>\n",
       "      <td>86.8</td>\n",
       "      <td>99.560025</td>\n",
       "      <td>16.1</td>\n",
       "      <td>87.980708</td>\n",
       "      <td>40.1</td>\n",
       "      <td>97.854785</td>\n",
       "      <td>94.581328</td>\n",
       "      <td>9.808662</td>\n",
       "      <td>99.987388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>0.046178</td>\n",
       "      <td>53.018046</td>\n",
       "      <td>12.54</td>\n",
       "      <td>84.019461</td>\n",
       "      <td>24.117036</td>\n",
       "      <td>73.515868</td>\n",
       "      <td>278.756235</td>\n",
       "      <td>29.113135</td>\n",
       "      <td>...</td>\n",
       "      <td>75.136648</td>\n",
       "      <td>61.3</td>\n",
       "      <td>85.568825</td>\n",
       "      <td>19.6</td>\n",
       "      <td>94.973981</td>\n",
       "      <td>21.1</td>\n",
       "      <td>63.544047</td>\n",
       "      <td>86.701266</td>\n",
       "      <td>8.991455</td>\n",
       "      <td>97.729852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2206</td>\n",
       "      <td>96-100% (highest scores)</td>\n",
       "      <td>0.064889</td>\n",
       "      <td>98.182950</td>\n",
       "      <td>15.40</td>\n",
       "      <td>97.218064</td>\n",
       "      <td>18.845944</td>\n",
       "      <td>58.220286</td>\n",
       "      <td>1000.240794</td>\n",
       "      <td>98.640389</td>\n",
       "      <td>...</td>\n",
       "      <td>73.723504</td>\n",
       "      <td>66.4</td>\n",
       "      <td>90.232558</td>\n",
       "      <td>18.6</td>\n",
       "      <td>93.654017</td>\n",
       "      <td>28.1</td>\n",
       "      <td>83.980706</td>\n",
       "      <td>80.075199</td>\n",
       "      <td>8.304296</td>\n",
       "      <td>92.773364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Total Population  CES 3.0 Percentile Range     Ozone  Ozone Pctl  PM2.5  \\\n",
       "0              3174  96-100% (highest scores)  0.064889   98.182950  15.40   \n",
       "1              6133  96-100% (highest scores)  0.062163   91.101431  13.31   \n",
       "2              3167  96-100% (highest scores)  0.062163   91.101431  15.40   \n",
       "3              6692  96-100% (highest scores)  0.046178   53.018046  12.54   \n",
       "4              2206  96-100% (highest scores)  0.064889   98.182950  15.40   \n",
       "\n",
       "   PM2.5 Pctl  Diesel PM  Diesel PM Pctl  Drinking Water  Drinking Water Pctl  \\\n",
       "0   97.218064  48.523809       95.544493      681.195604            80.915554   \n",
       "1   93.637725  38.556339       92.121966      904.657603            96.108270   \n",
       "2   97.218064  47.445208       95.420037      681.195604            80.915554   \n",
       "3   84.019461  24.117036       73.515868      278.756235            29.113135   \n",
       "4   97.218064  18.845944       58.220286     1000.240794            98.640389   \n",
       "\n",
       "        ...         Linguistic Isolation Pctl  Poverty  Poverty Pctl  \\\n",
       "0       ...                         77.509665     76.3     97.121307   \n",
       "1       ...                         96.253833     72.5     94.632307   \n",
       "2       ...                         78.389548     86.8     99.560025   \n",
       "3       ...                         75.136648     61.3     85.568825   \n",
       "4       ...                         73.723504     66.4     90.232558   \n",
       "\n",
       "   Unemployment  Unemployment Pctl  Housing Burden  Housing Burden Pctl  \\\n",
       "0          17.6          91.724838            26.0            79.398324   \n",
       "1          12.3          71.823836            34.1            93.754760   \n",
       "2          16.1          87.980708            40.1            97.854785   \n",
       "3          19.6          94.973981            21.1            63.544047   \n",
       "4          18.6          93.654017            28.1            83.980706   \n",
       "\n",
       "   Pop. Char.   Pop. Char. Score  Pop. Char. Pctl  \n",
       "0    92.120494          9.553440        99.697314  \n",
       "1    87.436849          9.067783        98.108210  \n",
       "2    94.581328          9.808662        99.987388  \n",
       "3    86.701266          8.991455        97.729852  \n",
       "4    80.075199          8.304296        92.773364  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns = ['Census Tract', 'CES 3.0 Score', ' CES 3.0 Percentile', \n",
    "                            'California County', 'ZIP', 'City', 'Longitude', 'Latitude'])\n",
    "data = data.dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need to do before we create our decision tree is to drop the `Pctl` columns, as well as create the testing, training, and validation sets.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.1.3:</b> Drop all columns that contain the string `Pctl` for our set of features. Don't forget to drop the percentile range column. We don't want that in our features! \n",
    "\n",
    "Assign the resulting table the variable `features` and assign the percentile ranges to the variable `target`.\n",
    "\n",
    "Lastly, create the training, testing, and validation sets by splitting the set into training and testing first, then split the training test. Use `random_state = 1` both times, and create an 80/20 train/test split, and a 75/25 train/validation split.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ...\n",
    "...\n",
    "\n",
    "features = ...\n",
    "target = ...\n",
    "\n",
    "# split test set\n",
    "X, X_test, y, y_test = train_test_split(...)\n",
    "\n",
    "# split between train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SOLUTION \n",
    "drop_columns = [i for i in data.columns if 'Pctl' in i]\n",
    "drop_columns.append('CES 3.0 Percentile Range')\n",
    "\n",
    "features = data.drop(columns=drop_columns)\n",
    "target = data['CES 3.0 Percentile Range']\n",
    "\n",
    "# split test set\n",
    "X, X_test, y, y_test = train_test_split(features, target, random_state = 1, test_size = .2)\n",
    "\n",
    "# split between train and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state = 1, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We can finally create a tree! \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.1.3:</b> Instantiate a `DecisionTreeClassifer` model and call it `first_tree`. Fit the model using the training data, and score it using both the training and validation set. Assign the scores to the variables `train_score` and `val_score` respectively.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "\n",
    "print(\"Number of features: {}\".format(first_tree.tree_.n_features))\n",
    "print(\"Number of nodes (leaves): {}\".format(first_tree.tree_.node_count), \"\\n\")\n",
    "\n",
    "...\n",
    "...\n",
    "\n",
    "print('Train Score: ', train_score)\n",
    "print('Validation Score: ', val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 25\n",
      "Number of nodes (leaves): 117 \n",
      "\n",
      "Train Score:  1.0\n",
      "Validation Score:  0.8963210702341137\n"
     ]
    }
   ],
   "source": [
    "#SOLUTION\n",
    "first_tree = DecisionTreeClassifier()\n",
    "first_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Number of features: {}\".format(first_tree.tree_.n_features))\n",
    "print(\"Number of nodes (leaves): {}\".format(first_tree.tree_.node_count), \"\\n\")\n",
    "\n",
    "train_score = first_tree.score(X_train, y_train)\n",
    "val_score = first_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', train_score)\n",
    "print('Validation Score: ', val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score isn't too shabby for a tree that was put together pretty quickly. The nice part about decision trees is that they're easy to visualize and interpret and with scikit-learn, we can export the an image of the tree. Unfortunately, due limitations on DataHub, we can't output an image directly in a notebook. \n",
    "\n",
    "Luckily, we can copy the code and visualize the tree on [Webgraphviz](http://webgraphviz.com). By running the following cell, you'll see a pretty long output -- follow the link and copy and paste the output to get a visualization of the decision tree we fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import graphviz\n",
    "print(tree.export_graphviz(first_tree, feature_names=X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.1.4:</b> What does each line in the box mean?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE*** <br>\n",
    "First line:\n",
    "\n",
    "Second line:\n",
    "\n",
    "Third line:\n",
    "\n",
    "Fourth Line:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.1.4:</b>   Based on the visualization, can you see any problems or pitfalls with the model we just created? Can you infer the \"most and least important\" features?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "<a name='first'></a>\n",
    "With scikit-learn, we're also able to check the feature importances. Running the following cell, we can see the features and the their importance based on the data we used to fit the tree -- this can be helpful when tuning or pruning the tree!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Feature': X.columns, 'Importance': first_tree.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "### 3.2. Tuning hyper parameters and Pruning\n",
    "\n",
    "We've had a good look at what we can do with a decision tree in using scikit-learn. Let's dive into learning about the hyperparameters, which can help improve our classification model. Again, the documentation for `DecisionTreeClassifier` is linked [here](http://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "If you noticed in the tree earlier, there were a *lot* of nodes. Some of these nodes have a gini score of 0 or have small sample numbers. We can overcome these problems by tweaking the hyperparameters of the tree. \n",
    "\n",
    "In the following cell, we have almost the exact same code from earlier, but we've added two parameters: `max_leaf_nodes` and `max_features`. Let's try two or three sets of different values for these two parameters and see how much we can improve our original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 25\n",
      "Number of nodes (leaves): 69 \n",
      "\n",
      "Train Score:  0.9787709497206704\n",
      "Validation Score:  0.9130434782608695\n"
     ]
    }
   ],
   "source": [
    "tuned_tree = DecisionTreeClassifier(max_leaf_nodes=..., max_features=...)\n",
    "tuned_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Number of features: {}\".format(tuned_tree.tree_.n_features))\n",
    "print(\"Number of nodes (leaves): {}\".format(tuned_tree.tree_.node_count),\"\\n\")\n",
    "\n",
    "tuned_train_score = tuned_tree.score(X_train, y_train)\n",
    "tuned_val_score = tuned_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', tuned_train_score)\n",
    "print('Validation Score: ', tuned_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Were you able to obtain validation score higher than what we had originally? It probably took some time to figure out which values were better than others.\n",
    "\n",
    "Fortunately, we don't have to test various parameters by manually inputting them and running the cell, which would be exhausting! Instead, we can use [`RandomizedSearchCV` from scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) to help us find optimal parameters. \n",
    "\n",
    "It takes in a model, a distribution of parameters we want to test in the model, and other parameters that we can tweak. We'll only use `cv` and `n_iter` along with the two required arguments. \n",
    "\n",
    "The parameter distribution is a dictionary that takes in the parameter name as a key and a range of random values that we want to test. We'll be using `randint` from scipy.stats. Run the following cell -- we will also fit the CV search which will take some time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {'max_leaf_nodes': randint(3, 100),\n",
    "              'max_features': randint(2, 25),\n",
    "              'max_depth': randint(1, 10)}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(tuned_tree, param_distributions=param_dist, \n",
    "                                cv=10, n_iter=200)\n",
    "rnd_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting our data, we can check the score and the values for the parameters that return the \"best\" score. Run the following cell to get these values!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(rnd_search.best_score_)\n",
    "print(rnd_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.2.1:</b> With our new parameters, set the parameters of `tuned_tree` to the ones that we found using the randomized search. Then, score the model using the training and validation sets.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "\n",
    "tuned_train_score = ...\n",
    "tuned_val_score = ...\n",
    "\n",
    "print('Train Score: ', tuned_train_score)\n",
    "print('Validation Score: ', tuned_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9832402234636871\n",
      "Validation Score:  0.8929765886287625\n"
     ]
    }
   ],
   "source": [
    "#SOLUTION (NOTE: parameters might be different for students)\n",
    "tuned_tree.set_params(max_features=18, max_leaf_nodes=40)\n",
    "tuned_tree.fit(X_train, y_train)\n",
    "\n",
    "tuned_train_score = tuned_tree.score(X_train, y_train)\n",
    "tuned_val_score = tuned_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', tuned_train_score)\n",
    "print('Validation Score: ', tuned_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! Hopefully this tuned tree performed better than our original one (due to the random samples, it's hard to say). Let's also print out the feature scores like we did initially. Do you see a difference between the feature importances of the tuned tree compared to those of the first tree?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Feature':X_train.columns, 'Importance': tuned_tree.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly, for this tuned tree, let's take a look at how adjusting the hyperparameters altered the decision tree. Like last time, copy and paste the code into [Webgraphviz](http://webgraphviz.com) to visualize the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(tree.export_graphviz(tuned_tree, feature_names=X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We briefly covered hyperparameter tuning -- let's move on to pruning our tree. Unfortunately, pruning is not a feature built into scikit-learn yet, but we can use the structure of the tree (which is readily available by calling `first_tree.tree_`) to traverse its nodes.\n",
    "\n",
    "The following is a function that prunes leaves and nodes based on how many samples we want a node to have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune(decision_tree, min_samples_leaf = 1):\n",
    "    decision_tree.min_samples_leaf = min_samples_leaf\n",
    "    tree = decision_tree.tree_\n",
    "    \n",
    "    for i in range(tree.node_count):\n",
    "        n_samples = tree.n_node_samples[i]\n",
    "        if n_samples <= min_samples_leaf:\n",
    "            #sklearn.tree structure: -1 denotes a leaf\n",
    "            tree.children_left[i] = -1\n",
    "            tree.children_right[i] = -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this pruned tree, let's compare it to the `first_tree` model -- so we won't set any specific hyperparameters.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.2.2:</b> Instantiate another model and assign it to `pruned_tree`. Fit it with the training data and then prune the tree -- try your best to find an optimal value. It doesn't necessarily have to be high, but try to find a better score than our initial model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "\n",
    "print(sum(pruned_tree.tree_.children_left < 0))\n",
    "\n",
    "...\n",
    "\n",
    "print(sum(pruned_tree.tree_.children_left < 0), '\\n')\n",
    "\n",
    "print('Train Score: ', pruned_tree.score(X_train, y_train))\n",
    "print('Validation Score: ', pruned_tree.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes before pruning:  59\n",
      "Nodes after pruning: 71 \n",
      "\n",
      "Train Score:  0.9832402234636871\n",
      "Validation Score:  0.903010033444816\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "pruned_tree = DecisionTreeClassifier()\n",
    "pruned_tree.fit(X_train, y_train)\n",
    "\n",
    "print(\"Nodes before pruning: \", sum(pruned_tree.tree_.children_left < 0))\n",
    "\n",
    "prune(pruned_tree, min_samples_leaf = 8)\n",
    "\n",
    "print('Nodes after pruning:', sum(pruned_tree.tree_.children_left < 0), '\\n')\n",
    "\n",
    "print('Train Score: ', pruned_tree.score(X_train, y_train))\n",
    "print('Validation Score: ', pruned_tree.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a look at the feature importances. Do they look any different from the previous two models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame({'Feature':X.columns, 'Importance': pruned_tree.feature_importances_})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell and copy and paste the output on [webgraphviz](http://webgraphviz.com)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tree.export_graphviz(pruned_tree, feature_names = X.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.2.3:</b> Take a look at each of the three trees. What did adjusting the hyperparameters do to the tree? What about the pruning? Does it make your model easier to understand?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 3.3. Binning\n",
    "\n",
    "Let's create another decision tree and use specific features to predict the environmental conditions of these communities. \n",
    "\n",
    "Take a look at the columns of the table. Notice that a lot of the features that we used in our first classification tree are *continuous*, not *discrete*. Let's say we wanted to make some sort of predictive model, using only those continuous values. Instead of predicting how impacted these communities are based on whichever group they fall under, we would be predicting their scores, which might not necessarily be helpful if we wanted to categorize these groups.\n",
    "\n",
    "What we can do to work around this is put certain scores into bins, or ranges, of values. In order to do so, we can either use the score of the characteristic or the percentile. Like we did in the first tree, we'll use the percentile, which gives us a better idea of how impacted a certain community is compared to other communities in this dataset.\n",
    "\n",
    "Run the following cell to take a subset of our data. For this section, our target variable will be `Pesticides Pctl`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pesticides Pctl</th>\n",
       "      <th>Linguistic Isolation</th>\n",
       "      <th>Education</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Housing Burden</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47.818560</td>\n",
       "      <td>16.2</td>\n",
       "      <td>53.3</td>\n",
       "      <td>17.6</td>\n",
       "      <td>76.3</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41.343490</td>\n",
       "      <td>33.4</td>\n",
       "      <td>53.3</td>\n",
       "      <td>12.3</td>\n",
       "      <td>72.5</td>\n",
       "      <td>34.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.753463</td>\n",
       "      <td>16.7</td>\n",
       "      <td>42.3</td>\n",
       "      <td>16.1</td>\n",
       "      <td>86.8</td>\n",
       "      <td>40.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.560942</td>\n",
       "      <td>15.3</td>\n",
       "      <td>40.8</td>\n",
       "      <td>19.6</td>\n",
       "      <td>61.3</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.152355</td>\n",
       "      <td>14.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>28.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.7</td>\n",
       "      <td>53.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>79.189751</td>\n",
       "      <td>27.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>14.4</td>\n",
       "      <td>76.2</td>\n",
       "      <td>24.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90.893352</td>\n",
       "      <td>15.8</td>\n",
       "      <td>47.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>31.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.7</td>\n",
       "      <td>50.4</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.7</td>\n",
       "      <td>31.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>76.835180</td>\n",
       "      <td>13.7</td>\n",
       "      <td>52.5</td>\n",
       "      <td>23.5</td>\n",
       "      <td>83.4</td>\n",
       "      <td>23.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pesticides Pctl  Linguistic Isolation  Education  Unemployment  Poverty  \\\n",
       "0        47.818560                  16.2       53.3          17.6     76.3   \n",
       "1        41.343490                  33.4       53.3          12.3     72.5   \n",
       "2        48.753463                  16.7       42.3          16.1     86.8   \n",
       "3        60.560942                  15.3       40.8          19.6     61.3   \n",
       "4        95.152355                  14.7       45.1          18.6     66.4   \n",
       "5         0.000000                  23.7       53.1          11.6     66.4   \n",
       "6        79.189751                  27.1       46.0          14.4     76.2   \n",
       "7        90.893352                  15.8       47.4          20.0     74.5   \n",
       "8         0.000000                  35.7       50.4          28.5     75.7   \n",
       "9        76.835180                  13.7       52.5          23.5     83.4   \n",
       "\n",
       "   Housing Burden  \n",
       "0            26.0  \n",
       "1            34.1  \n",
       "2            40.1  \n",
       "3            21.1  \n",
       "4            28.1  \n",
       "5            22.0  \n",
       "6            24.3  \n",
       "7            31.8  \n",
       "8            31.7  \n",
       "9            23.2  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['Pesticides Pctl', 'Linguistic Isolation', 'Education', 'Unemployment', \n",
    "           'Poverty', 'Housing Burden']\n",
    "pesticides = data[columns]\n",
    "pesticides.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can put the values in `Pesticides Pctl` into bins to \"classify\" a community's exposure to pesticides given certain demographic characteristics.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.3.1:</b> Take the top and bottom 20th percent of our data. Reassign the resulting dataframe to `pesticides`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pesticides Pctl</th>\n",
       "      <th>Linguistic Isolation</th>\n",
       "      <th>Education</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Pesticides Binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.152355</td>\n",
       "      <td>14.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>28.1</td>\n",
       "      <td>80-100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.7</td>\n",
       "      <td>53.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90.893352</td>\n",
       "      <td>15.8</td>\n",
       "      <td>47.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>31.8</td>\n",
       "      <td>80-100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.7</td>\n",
       "      <td>50.4</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.9</td>\n",
       "      <td>52.3</td>\n",
       "      <td>20.1</td>\n",
       "      <td>70.7</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.4</td>\n",
       "      <td>61.4</td>\n",
       "      <td>16.9</td>\n",
       "      <td>78.3</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>86.945983</td>\n",
       "      <td>27.1</td>\n",
       "      <td>53.8</td>\n",
       "      <td>21.8</td>\n",
       "      <td>77.5</td>\n",
       "      <td>21.1</td>\n",
       "      <td>80-100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>89.092798</td>\n",
       "      <td>13.6</td>\n",
       "      <td>44.3</td>\n",
       "      <td>18.5</td>\n",
       "      <td>76.5</td>\n",
       "      <td>26.8</td>\n",
       "      <td>80-100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.1</td>\n",
       "      <td>51.4</td>\n",
       "      <td>13.6</td>\n",
       "      <td>76.3</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.6</td>\n",
       "      <td>38.7</td>\n",
       "      <td>11.1</td>\n",
       "      <td>65.3</td>\n",
       "      <td>24.2</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pesticides Pctl  Linguistic Isolation  Education  Unemployment  Poverty  \\\n",
       "4         95.152355                  14.7       45.1          18.6     66.4   \n",
       "5          0.000000                  23.7       53.1          11.6     66.4   \n",
       "7         90.893352                  15.8       47.4          20.0     74.5   \n",
       "8          0.000000                  35.7       50.4          28.5     75.7   \n",
       "13         0.000000                  22.9       52.3          20.1     70.7   \n",
       "14         0.000000                  28.4       61.4          16.9     78.3   \n",
       "15        86.945983                  27.1       53.8          21.8     77.5   \n",
       "18        89.092798                  13.6       44.3          18.5     76.5   \n",
       "20         0.000000                  17.1       51.4          13.6     76.3   \n",
       "21         0.000000                  26.6       38.7          11.1     65.3   \n",
       "\n",
       "    Housing Burden Pesticides Binned  \n",
       "4             28.1           80-100%  \n",
       "5             22.0          0-19.99%  \n",
       "7             31.8           80-100%  \n",
       "8             31.7          0-19.99%  \n",
       "13            31.2          0-19.99%  \n",
       "14            24.6          0-19.99%  \n",
       "15            21.1           80-100%  \n",
       "18            26.8           80-100%  \n",
       "20            38.7          0-19.99%  \n",
       "21            24.2          0-19.99%  "
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SOLUTION\n",
    "pesticides = pesticides.loc[(pesticides['Pesticides Pctl'] >= 80) | (pesticides['Pesticides Pctl'] < 20)]\n",
    "pesticides.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the values in `Pesticides Pctl` is still continuous, let's put them into two bins: the bottom 20% will go into the bin `0-19.99%` and the top 20% will go into `80-100%`.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 3.3.2:</b> Complete the for loop to put each observation into their respective category. \n",
    "\n",
    "Make sure that your code is correct by verifying that the percentile group for the first 10 rows correspond with the percentile in the first column.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = ['0-19.99%', '80-100%']\n",
    "binned = []\n",
    "for pctl in pesticides['Pesticides Pctl'] // 10:\n",
    "    ...\n",
    "\n",
    "\n",
    "...\n",
    "pesticides.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pesticides Pctl</th>\n",
       "      <th>Linguistic Isolation</th>\n",
       "      <th>Education</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Poverty</th>\n",
       "      <th>Housing Burden</th>\n",
       "      <th>Pesticides Binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.152355</td>\n",
       "      <td>14.7</td>\n",
       "      <td>45.1</td>\n",
       "      <td>18.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>28.1</td>\n",
       "      <td>80-100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>23.7</td>\n",
       "      <td>53.1</td>\n",
       "      <td>11.6</td>\n",
       "      <td>66.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>90.893352</td>\n",
       "      <td>15.8</td>\n",
       "      <td>47.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>31.8</td>\n",
       "      <td>80-100%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>35.7</td>\n",
       "      <td>50.4</td>\n",
       "      <td>28.5</td>\n",
       "      <td>75.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>22.9</td>\n",
       "      <td>52.3</td>\n",
       "      <td>20.1</td>\n",
       "      <td>70.7</td>\n",
       "      <td>31.2</td>\n",
       "      <td>0-19.99%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pesticides Pctl  Linguistic Isolation  Education  Unemployment  Poverty  \\\n",
       "4         95.152355                  14.7       45.1          18.6     66.4   \n",
       "5          0.000000                  23.7       53.1          11.6     66.4   \n",
       "7         90.893352                  15.8       47.4          20.0     74.5   \n",
       "8          0.000000                  35.7       50.4          28.5     75.7   \n",
       "13         0.000000                  22.9       52.3          20.1     70.7   \n",
       "\n",
       "    Housing Burden Pesticides Binned  \n",
       "4             28.1           80-100%  \n",
       "5             22.0          0-19.99%  \n",
       "7             31.8           80-100%  \n",
       "8             31.7          0-19.99%  \n",
       "13            31.2          0-19.99%  "
      ]
     },
     "execution_count": 621,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SOLTUION\n",
    "bins = ['0-19.99%', '80-100%']\n",
    "binned = []\n",
    "for pctl in pesticides['Pesticides Pctl'] // 10:\n",
    "    if pctl < 2:\n",
    "        binned.append(bins[0])\n",
    "    else:\n",
    "        binned.append(bins[1])\n",
    "\n",
    "pesticides['Pesticides Binned'] = binned\n",
    "pesticides.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our categorized numerical values, we can fit a model and make some predictions! Run the following cell to fit and score a decision tree with the data we crafted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 5\n",
      "Number of nodes (leaves): 141 \n",
      "\n",
      "Train Score:  1.0\n",
      "Validation Score:  0.9\n"
     ]
    }
   ],
   "source": [
    "p_X = pesticides.drop(columns=['Pesticides Pctl', 'Pesticides Binned'])\n",
    "p_y = pesticides['Pesticides Binned']\n",
    "\n",
    "p_X_train, p_X_test, p_y_train, p_y_test = train_test_split(p_X, p_y, random_state = 2,\n",
    "                                                           test_size=.25)\n",
    "second_tree = DecisionTreeClassifier()\n",
    "second_tree.fit(p_X_train, p_y_train)\n",
    "\n",
    "print(\"Number of features: {}\".format(second_tree.tree_.n_features))\n",
    "print(\"Number of nodes (leaves): {}\".format(second_tree.tree_.node_count), '\\n')\n",
    "\n",
    "print('Train Score: ', second_tree.score(p_X_train, p_y_train))\n",
    "print('Validation Score: ', second_tree.score(p_X_test, p_y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to more improvements we can make to decision tree models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## 4. Ensemble Methods <a name = 'improve'></a>\n",
    "\n",
    "In the previous section, we mainly were focusing on fitting one tree and editing it's hyperparameters or pruning it. Otherwise, we do anything more to alter it. Also, you may have noticed that, although the training scores were  extremely high, the validation scores usually weren't as high. This is where ensemble methods come in, namely bagging, random forests, and boosting. We call them \"ensemble methods\" because we fit a many trees and, for example in bagging, we take the average of all of the models as a means to reduce the problem of overfitting.\n",
    "\n",
    "----\n",
    "\n",
    "### 4.1. Bagging\n",
    "\n",
    "Bagging takes in $B$ different bootstrapped training data sets and we train our tree on each $b$th training set to get $\\hat{f}^{*b}(x)$. Then, we average all of the predictions to get \n",
    "\n",
    "$$\\hat{f}_{bag}(x) = \\frac{1}{B} \\sum_{b=1}^{B}\\hat{f}^{*b}(x)$$\n",
    "\n",
    "In terms of classifying, bagging records the class from each bootstrapped sample and chooses the most commonly occurring majority class among the B predictions.\n",
    "\n",
    "Let's proceed by using `BaggingClassifier` from scikit-learn's ensemble module ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)). \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.1.1:</b> Use the training data and fit the bagging classifier. Score the model -- how much has the score improved?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "...\n",
    "...\n",
    "\n",
    "bag_train_score = ...\n",
    "bag_val_score = ...\n",
    "\n",
    "print('Train Score: ', bag_train_score)\n",
    "print('Validation Score: ', bag_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9910614525139665\n",
      "Validation Score:  0.8929765886287625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag_tree = BaggingClassifier()\n",
    "bag_tree.fit(X_train, y_train)\n",
    "\n",
    "bag_train_score = bag_tree.score(X_train, y_train)\n",
    "bag_val_score = bag_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', bag_train_score)\n",
    "print('Validation Score: ', bag_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like before, we can use the randomized parameter search to find optimal parameters for our model.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.1.2:</b> Create a dictionary for the parameter distribution and fit a `RandomizedSearchCV` with `cv = 10` and `n_iter = 50`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = {}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(...)\n",
    "\n",
    "...\n",
    "\n",
    "print(rnd_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=13, max_samples=529,\n",
       "         n_estimators=26, n_jobs=None, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=20, n_jobs=None,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1258cd7b8>, 'max_samples': <scipy.stats._distn_infrastructure.rv_frozen object at 0x1258cd518>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 630,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "param_dist = {'n_estimators': randint(10, 100),\n",
    "              'max_samples': randint(5, 700)}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(bag_tree, param_distributions=param_dist, \n",
    "                                cv=10, n_iter=20)\n",
    "rnd_search.fit(X_train, y_train)\n",
    "\n",
    "print(rnd_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.1.2:</b> Set the parameters in `bag_tree` and re-score the model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "\n",
    "bag_train_score = ...\n",
    "bag_val_score = ...\n",
    "\n",
    "print('Train Score: ', bag_train_score)\n",
    "print('Validation Score: ', bag_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 646,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9955307262569832\n",
      "Validation Score:  0.9297658862876255\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "bag_tree.set_params(max_samples=622, n_estimators=58, max_features=25)\n",
    "\n",
    "bag_train_score = bag_tree.score(X_train, y_train)\n",
    "bag_val_score = bag_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', bag_train_score)\n",
    "print('Validation Score: ', bag_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that bagging the model has a better score than the first model we created. Even if we get a better model in the end, there are still some consequences.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.1.3:</b> What are some drawbacks of bagging compared to a single decision tree? Is there a way to compare the quality of a single decision tree model compared to a bagged model?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 4.2. Random Forests\n",
    "\n",
    "Random forests take a similar approach to bagging, in which we fit various decision trees on resampled data. But, when each tree is constructed, not every feature is considered as split candidates for each decision point; we only take a subset of the total predictors in the model.\n",
    "\n",
    "When building a random forest compared to a single decision tree, adding randomization into the features that create the model, then averaging the predictions across models will typically produce a model \"decorrelates\" the trees and in turn is more reliable for prediction.\n",
    "\n",
    "We'll use scikit-learn's `RandomForestClassifier()` to implement our model. The documentation can be found [here](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.2.1: </b>  Create a default RandomForestClassifier and same as before, fit the training data and score the model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "...\n",
    "...\n",
    "\n",
    "rf_train_score = ...\n",
    "rf_val_score = ...\n",
    "\n",
    "print('Train Score: ', rf_train_score)\n",
    "print('Validation Score: ', rf_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9955307262569832\n",
      "Validation Score:  0.9096989966555183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/ensemble/forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_tree = RandomForestClassifier()\n",
    "rf_tree.fit(X_train, y_train)\n",
    "\n",
    "rf_train_score = rf_tree.score(X_train, y_train)\n",
    "rf_val_score = rf_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', rf_train_score)\n",
    "print('Validation Score: ', rf_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.2.2: </b>  We'll use RandomizedSearchCV again to find values for our hyperparameters. Look at the documentation to see which parameters we can find using the random search. Then, find the cross-validated parameters and print them. \n",
    "\n",
    "Note: This might take some time, so feel free to move onto the next question while it's working.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dist = ...\n",
    "\n",
    "...\n",
    "\n",
    "...\n",
    "\n",
    "print(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=None,\n",
       "          param_distributions={'n_estimators': <scipy.stats._distn_infrastructure.rv_frozen object at 0x121f24358>, 'max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x121f24208>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x121f246d8>, 'max_depth': <scipy.st...21f24320>, 'min_samples_split': <scipy.stats._distn_infrastructure.rv_frozen object at 0x121f249e8>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#solution\n",
    "param_dist = {'n_estimators': randint(10, 100),\n",
    "              'max_leaf_nodes': randint(3, 100),\n",
    "              'max_features': randint(2, 27),\n",
    "              'max_depth': randint(1, 10),\n",
    "              'min_samples_leaf': randint(1, 30),\n",
    "              'min_samples_split': randint(2, 20)}\n",
    "\n",
    "rnd_search = RandomizedSearchCV(rf_tree, param_distributions=param_dist, \n",
    "                                cv=10, n_iter=50)\n",
    "rnd_search.fit(X_train, y_train)\n",
    "\n",
    "print(rnd_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that we can choose the number of features or predictors that the random forest will consider in each tree. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.2.3: </b>  What if the number of predictors we set is equal to the total number predictors in our regular model? Which method would it be equivalent to?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.2.4: </b> Once the search has completed and you've printed the parameters, set them in the `rf_tree` model and re-fit the model, and print out the scores.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "\n",
    "rf_train_score = ...\n",
    "rf_val_score = ...\n",
    "\n",
    "print('Train Score: ', rf_train_score)\n",
    "print('Validation Score: ', rf_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.982122905027933\n",
      "0.9331103678929766\n"
     ]
    }
   ],
   "source": [
    "rf_tree.set_params(max_features=11, max_leaf_nodes=59, \n",
    "                   min_samples_leaf=7, min_samples_split=14, n_estimators=100)\n",
    "rf_tree.fit(X_train, y_train)\n",
    "\n",
    "rf_train_score = rf_tree.score(X_train, y_train)\n",
    "rf_val_score = rf_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', rf_train_score)\n",
    "print('Validation Score: ', rf_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to bagging, we cannot visualize a random forest; with a reduction in variance comes at a price of interpretability. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### 4.3. Boosting\n",
    "\n",
    "Lastly, we'll cover boosting, which is yet another approach to improve a decision tree model. The boosting approach grows a tree slowly. Each boosting algorithm has a slightly different approach, but the general idea is the same behind each one.\n",
    "\n",
    "First, we'll briefly cover AdaBoost (for ADAptive BOOSTing). The adaptive part of the algorithm comes from how it updates the data for each weak model in the sequence; it combines many relatively weak and inaccurate classifiers. So it shines when a regular classifier doesn't perform well with a given dataset.\n",
    "\n",
    "We can use `AdaBoostClassifier` from scikit-learn to try this out. Run the following cell to see how it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.5184357541899441\n",
      "Validation Score:  0.46488294314381273\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_tree = AdaBoostClassifier()\n",
    "ada_tree.fit(X_train, y_train)\n",
    "\n",
    "ada_train_score = ada_tree.score(X_train, y_train)\n",
    "ada_val_score = ada_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', ada_train_score)\n",
    "print('Validation Score: ', ada_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oops. It doesn't look too great. One thing with AdaBoost is that it doesn't handle noisy data or outliers well. In this case, our data is basically polarized -- we're taking values from the top and bottom 10% -- which means it might not work as well as we want it to.\n",
    "\n",
    "We can turn to gradient boosting, which is another boosting method. Gradient boosting involves three elements:\n",
    "1. A loss function to be optimized.\n",
    "2. A weak learner to make predictions.\n",
    "3. An additive model in which we add weak learners to minimize the loss function.\n",
    "\n",
    "We'll use scikit-learn's `GradientBoostingClassifier` ([documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)) to see how it performs with our data.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.3.1: </b> We'll do this the last time! Fit the training data to the GradientBoostingClassifier and score the model. How much did it improve over the original model?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "...\n",
    "...\n",
    "\n",
    "gb_train_score = ...\n",
    "gb_val_score = ...\n",
    "\n",
    "print('Train Score: ', gb_train_score)\n",
    "print('Validation Score: ', gb_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Validation Score:  0.9096989966555183\n"
     ]
    }
   ],
   "source": [
    "# solution\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gb_tree = GradientBoostingClassifier()\n",
    "gb_tree.fit(X_train, y_train)\n",
    "\n",
    "gb_train_score = gb_tree.score(X_train, y_train)\n",
    "gb_val_score = gb_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', gb_train_score)\n",
    "print('Validation Score: ', gb_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also improve the model by tuning the hyperparameters. Since we've done this quite a bit, we've coded the cell for running the search -- just run the following cell!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=5,\n",
       "              max_features=26, max_leaf_nodes=83,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=3, min_samples_s...      subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=False),\n",
       "          fit_params=None, iid='warn', n_iter=50, n_jobs=None,\n",
       "          param_distributions={'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen object at 0x122023860>, 'max_leaf_nodes': <scipy.stats._distn_infrastructure.rv_frozen object at 0x121f25588>, 'max_features': <scipy.stats._distn_infrastructure.rv_frozen object at 0x121f40080>, 'max_depth': <scipy.stats._distn_infrastructure.rv_frozen object at 0x121f401d0>, 'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_frozen object at 0x121f40518>},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dist = {'learning_rate': randint(1, 5),\n",
    "              'max_leaf_nodes': randint(3, 100),\n",
    "              'max_features': randint(2, 27),\n",
    "              'max_depth': randint(1, 10),\n",
    "              'min_samples_leaf': randint(1, 30)}\n",
    "\n",
    "rnd_gb_search = RandomizedSearchCV(gb_tree, param_distributions=param_dist, \n",
    "                                cv=10, n_iter=50)\n",
    "\n",
    "rnd_gb_search.fit(X_train, y_train)\n",
    "\n",
    "print(rnd_gb_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.3.2: </b> Once the search is complete, set the parameters and re-fit and score the model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "\n",
    "gb_train_score = ...\n",
    "gb_val_score = ...\n",
    "\n",
    "print('Train Score: ', gb_train_score)\n",
    "print('Validation Score: ', gb_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  1.0\n",
      "Validation Score:  0.9264214046822743\n"
     ]
    }
   ],
   "source": [
    "# SOLUTION\n",
    "gb_tree.set_params(learning_rate=.1, max_depth=8, max_features=19, max_leaf_nodes=63, \n",
    "                   min_samples_leaf=8, n_estimators=76)\n",
    "gb_tree.fit(X_train, y_train)\n",
    "\n",
    "print('Train Score: ', gb_tree.score(X_train, y_train))\n",
    "print('Validation Score: ', gb_tree.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With boosting, we can also find the relative feature importance with this boosted model. This can help with the feature importance like before. \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.3.3: </b>  Get the feature importances and calculate the *relative* feature importance, which is each feature divided by the maximum feature multiplied by 100. Load the data into a table.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "...\n",
    "...\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "feature_importance = gb_tree.feature_importances_\n",
    "#relative feature importance\n",
    "feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "gb_feat = pd.DataFrame({'feature':X_train.columns, 'importance':feature_importance})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.3.4: </b> Let's take a look at how these features compare with each other. Sort the values in the dataframe and create a bar chart that displays the feature importances in descending order.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION\n",
    "gb_feat = gb_feat.sort_values(by='importance', ascending=True)\n",
    "\n",
    "plt.figure(figsize=(8, 7.5))\n",
    "plt.barh(width=gb_feat.importance, y=gb_feat.feature);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "<b>Question 4.3.5: </b> Lastly, compare these values with the values we computed the [very first time](#first). Are these values similar? If not, which one does a better job indicating which features are more important?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***YOUR ANSWER HERE***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "We've gone through many methods of creating a decision tree and tuning and improving it, as well as various algorithms that use multiple trees to create a more reliable tree for prediction. Even though we've primarily have been testing our models with the training and validation set, we would still need to cross validate each of these models to see which one is the optimal one to choose given our data and how the model performs (this is even more important when a lot of the scores turned up around 92-93%). \n",
    "\n",
    "Before you finish up this homework, run the following cell to see which has the highest score with our test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Score:  0.9063545150501672\n",
      "Test Score:  0.9230769230769231\n",
      "Test Score:  0.9230769230769231\n",
      "Test Score:  0.9264214046822743\n",
      "Test Score:  0.939799331103679\n",
      "Test Score:  0.4682274247491639\n",
      "Test Score:  0.9565217391304348\n"
     ]
    }
   ],
   "source": [
    "models = [first_tree, tuned_tree, pruned_tree, bag_tree, rf_tree, ada_tree, gb_tree]\n",
    "for i in models:\n",
    "    print('Test Score: ', i.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Submission\n",
    "\n",
    "Congrats, you're done with homework 10! \n",
    "\n",
    "In order to turn in this assignment, go to the toolbar and click **File** -> **Download as** -> **.html** and **.ipynb**. Submit the files through bCourses.\n",
    "\n",
    "----\n",
    "\n",
    "Notebook developed by: Jason Jiang\n",
    "\n",
    "Data Science Modules: http://data.berkeley.edu/education/modules"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
